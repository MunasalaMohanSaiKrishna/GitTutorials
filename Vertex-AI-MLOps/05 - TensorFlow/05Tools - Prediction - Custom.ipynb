{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff39d602-2dc8-40e0-93e8-15048a655918",
   "metadata": {},
   "source": [
    "# 05Tools: Prediction - Custom\n",
    "\n",
    "Predictions from models created in the 05 series of notebooks.\n",
    "\n",
    "This notebook is part of collection of examples that showcase many ways to serve models:\n",
    "- Online:\n",
    "    - Vertex AI Endpoints: Python, REST, CLI (gcloud): [05Tools - Prediction - Online.ipynb](./05Tools%20-%20Prediction%20-%20Online.ipynb)\n",
    "    - Local with TensorFlow ModelServer: [05Tools - Prediction - Local.ipynb](./05Tools%20-%20Prediction%20-%20Local.ipynb)\n",
    "    - (**THIS NOTEBOOK**) Custom: Build a custom container with TensorFlow ModelServer: [05Tools - Prediction - Custom.ipynb](./05Tools%20-%20Prediction%20-%20Custom.ipynb)\n",
    "        - Remote Service with Cloud Run\n",
    "        - Local Service with Docker Run\n",
    "- Batch: [05Tools - Prediction - Batch.ipynb](./05Tools%20-%20Prediction%20-%20Batch.ipynb)\n",
    "    - BigQuery ML Model Import\n",
    "    - Vertex AI Batch Prediction Jobs\n",
    "\n",
    "**Prerequisites:**\n",
    "-  At least 1 of the notebooks in this series [05, 05a-05i]\n",
    "\n",
    "**Conceptual Flow & Workflow**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img alt=\"Conceptual Flow\" src=\"../architectures/slides/05tools_pred_arch.png\" width=\"45%\">\n",
    "&nbsp; &nbsp; &nbsp; &nbsp;\n",
    "  <img alt=\"Workflow\" src=\"../architectures/slides/05tools_pred_console.png\" width=\"45%\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c887ebb-9310-4bea-a40d-2c1c3bd92e8d",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535c18bd-568b-4ebf-a142-a16cd126ed8a",
   "metadata": {},
   "source": [
    "### Package Installs (if needed)\n",
    "\n",
    "This notebook uses the Python Clients for\n",
    "- Google Service Usage\n",
    "    - to enable APIs (Artifact Registry and Cloud Build)\n",
    "- Artifact Registry\n",
    "    - to create repositories for Docker containers\n",
    "- Cloud Build\n",
    "    - To build custom Docker containers\n",
    "\n",
    "The cells below check to see if the required Python libraries are installed.  If any are not it will print a message to do the install with the associated pip command to use.  These installs must be completed before continuing this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9be315c2-8eb7-4508-a31d-d02661e3723f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.cloud.service_usage_v1\n",
    "except ImportError:\n",
    "    print('You need to pip install google-cloud-service-usage')\n",
    "    !pip install google-cloud-service-usage -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13aa18a2-145c-4e8b-9bbb-8997d696820b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.cloud.artifactregistry_v1\n",
    "except ImportError:\n",
    "    print('You need to pip install google-cloud-artifact-registry')\n",
    "    !pip install google-cloud-artifact-registry -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3056bf25-33cb-4179-abc3-e5a632a6cc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.cloud.devtools.cloudbuild\n",
    "except ImportError:\n",
    "    print('You need to pip install google-cloud-build')\n",
    "    !pip install google-cloud-build"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae56bf29-6fcf-4e93-aaf1-1e8d199396d2",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e3409f-ce92-42cb-bfd6-026e2ffe33b1",
   "metadata": {},
   "source": [
    "inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09efe29d-f542-46e3-a615-e0f73e92cfe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f986894-0c7e-48ce-afb3-7417f8fd7ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "EXPERIMENT = '05_predictions'\n",
    "SERIES = '05'\n",
    "\n",
    "# source data\n",
    "BQ_PROJECT = PROJECT_ID\n",
    "BQ_DATASET = 'fraud'\n",
    "BQ_TABLE = 'fraud_prepped'\n",
    "\n",
    "# Resources\n",
    "DEPLOY_COMPUTE = 'n1-standard-4'\n",
    "DEPLOY_IMAGE='us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-7:latest'\n",
    "\n",
    "# Model Training\n",
    "VAR_TARGET = 'Class'\n",
    "VAR_OMIT = 'transaction_id' # add more variables to the string with space delimiters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b958e5fb-e042-4c46-8263-130acb8a8d13",
   "metadata": {},
   "source": [
    "packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd739ffa-dc12-435c-ae32-0828be873a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import service_usage_v1\n",
    "from google.cloud.devtools import cloudbuild_v1\n",
    "from google.cloud import artifactregistry_v1\n",
    "from google.cloud import storage\n",
    "\n",
    "import tensorflow as tf\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a1e2a6-483e-459e-b54b-f6cb8510738b",
   "metadata": {},
   "source": [
    "clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f474d80a-4ae9-438a-98f6-da2b6b49fb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "bq = bigquery.Client()\n",
    "gcs = storage.Client()\n",
    "su_client = service_usage_v1.ServiceUsageClient()\n",
    "ar_client = artifactregistry_v1.ArtifactRegistryClient()\n",
    "cb_client = cloudbuild_v1.CloudBuildClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9282268d-08ed-42fc-a854-c0af0b32e149",
   "metadata": {},
   "source": [
    "parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b1efd68-cb82-466b-8741-34fcac59cfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = PROJECT_ID\n",
    "DIR = f\"temp/{EXPERIMENT}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee36e2f-d42d-49d5-a030-35b13a0b5547",
   "metadata": {},
   "source": [
    "environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "951463c0-2c6b-4676-90c7-551756e7fa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {DIR}\n",
    "!mkdir -p {DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ac1bb6-5c35-4ce6-8822-17ebbd2a9983",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Enable APIs\n",
    "\n",
    "Using Cloud Build and Artifact Registry requires enabling these APIs for the Google Cloud Project.\n",
    "\n",
    "Options for enabeling these.  In this notebook option 2 is used.\n",
    " 1. Use the APIs & Services page in the console: https://console.cloud.google.com/apis\n",
    "     - `+ Enable APIs and Services`\n",
    "     - Search for Cloud Build and Enable\n",
    "     - Search for Artifact Registry and Enable\n",
    " 2. Use [Google Service Usage](https://cloud.google.com/service-usage/docs) API from Python\n",
    "     - [Python Client For Service Usage](https://github.com/googleapis/python-service-usage)\n",
    "     - [Python Client Library Documentation](https://cloud.google.com/python/docs/reference/serviceusage/latest)\n",
    "     \n",
    "The following code cells use the Service Usage Client to:\n",
    "- get the state of the service\n",
    "- if 'DISABLED':\n",
    "    - Try enabling the service and return the state after trying\n",
    "- if 'ENABLED' print the state for confirmation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6c9d4c-8c88-4cdc-af59-e780ead130f4",
   "metadata": {},
   "source": [
    "#### Artifact Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80db6a0e-628e-4c0f-88c2-d0643d12057a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifact Registry already enabled for project: statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "artifactregistry = su_client.get_service(\n",
    "    request = service_usage_v1.GetServiceRequest(\n",
    "        name = f'projects/{PROJECT_ID}/services/artifactregistry.googleapis.com'\n",
    "    )\n",
    ").state.name\n",
    "\n",
    "\n",
    "if artifactregistry == 'DISABLED':\n",
    "    print(f'Artifact Registry is currently {artifactregistry} for project: {PROJECT_ID}')\n",
    "    print(f'Trying to Enable...')\n",
    "    operation = su_client.enable_service(\n",
    "        request = service_usage_v1.EnableServiceRequest(\n",
    "            name = f'projects/{PROJECT_ID}/services/artifactregistry.googleapis.com'\n",
    "        )\n",
    "    )\n",
    "    response = operation.result()\n",
    "    if response.service.state.name == 'ENABLED':\n",
    "        print(f'Artifact Registry is now enabled for project: {PROJECT_ID}')\n",
    "    else:\n",
    "        print(response)\n",
    "else:\n",
    "    print(f'Artifact Registry already enabled for project: {PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7032bae5-efc6-4e46-9b04-a06b486e9f62",
   "metadata": {},
   "source": [
    "#### Cloud Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67f775a2-0f2a-4775-9dad-d33584cc6845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloud Build already enabled for project: statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "cloudbuild = su_client.get_service(\n",
    "    request = service_usage_v1.GetServiceRequest(\n",
    "        name = f'projects/{PROJECT_ID}/services/cloudbuild.googleapis.com'\n",
    "    )\n",
    ").state.name\n",
    "\n",
    "\n",
    "if cloudbuild == 'DISABLED':\n",
    "    print(f'Cloud Build is currently {cloudbuild} for project: {PROJECT_ID}')\n",
    "    print(f'Trying to Enable...')\n",
    "    operation = su_client.enable_service(\n",
    "        request = service_usage_v1.EnableServiceRequest(\n",
    "            name = f'projects/{PROJECT_ID}/services/cloudbuild.googleapis.com'\n",
    "        )\n",
    "    )\n",
    "    response = operation.result()\n",
    "    if response.service.state.name == 'ENABLED':\n",
    "        print(f'Cloud Build is now enabled for project: {PROJECT_ID}')\n",
    "    else:\n",
    "        print(response)\n",
    "else:\n",
    "    print(f'Cloud Build already enabled for project: {PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba15970c-9ad2-420e-8590-a0b990aac10c",
   "metadata": {},
   "source": [
    "#### Cloud Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ee53d4ce-66b1-4ee1-9507-746b0364cc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloud Run already enabled for project: statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "cloudrun = su_client.get_service(\n",
    "    request = service_usage_v1.GetServiceRequest(\n",
    "        name = f'projects/{PROJECT_ID}/services/run.googleapis.com'\n",
    "    )\n",
    ").state.name\n",
    "\n",
    "\n",
    "if cloudrun == 'DISABLED':\n",
    "    print(f'Cloud Run is currently {cloudrun} for project: {PROJECT_ID}')\n",
    "    print(f'Trying to Enable...')\n",
    "    operation = su_client.enable_service(\n",
    "        request = service_usage_v1.EnableServiceRequest(\n",
    "            name = f'projects/{PROJECT_ID}/services/run.googleapis.com'\n",
    "        )\n",
    "    )\n",
    "    response = operation.result()\n",
    "    if response.service.state.name == 'ENABLED':\n",
    "        print(f'Cloud Run is now enabled for project: {PROJECT_ID}')\n",
    "    else:\n",
    "        print(response)\n",
    "else:\n",
    "    print(f'Cloud Run already enabled for project: {PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe30d5d-1c03-486d-b1b7-c3794f7916b5",
   "metadata": {},
   "source": [
    "---\n",
    "## Get a Model For Predictions\n",
    "This project already has a model serving online predictions at a Vertex AI Endpoint.  This section will use the endpoint to retrieve the deployed model and get its information to use for batch prediction methods in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a25530e-0249-4714-ba43-4abd06498c5c",
   "metadata": {},
   "source": [
    "### Get Endpoint\n",
    "\n",
    "[Endpoint Properties and Methods](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.Endpoint):\n",
    "\n",
    "```python\n",
    "endpoint\n",
    "endpoint.display_name\n",
    "endpoint.resource_name\n",
    "endpoint.traffic_split\n",
    "endpoint.list_models()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dae75e08-4c05-4b50-9eb6-55ad851c404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoints = aiplatform.Endpoint.list(filter = f\"labels.series={SERIES}\")\n",
    "endpoint = endpoints[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8dc802ff-cc5b-484c-8f1c-7aea6a89f9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review the Endpoint in the Console:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/endpoints/1961322035766362112?project=statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "print(f'Review the Endpoint in the Console:\\nhttps://console.cloud.google.com/vertex-ai/locations/{REGION}/endpoints/{endpoint.name}?project={PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1475fb-95e9-400e-a337-c02178c715ac",
   "metadata": {},
   "source": [
    "### Get Model at Endpoint\n",
    "Using the model on the endpoint for the current series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "909d9897-ab16-43eb-8baf-1aa860437396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.models.Endpoint object at 0x7f6ed44694d0> \n",
       "resource name: projects/1026793852137/locations/us-central1/endpoints/1961322035766362112"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1df783a-386f-4782-aebe-3edec7a2efec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#endpoint.list_models()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "418340ff-c687-4370-b748-e6fd16e1133c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = aiplatform.Model(\n",
    "    model_name = endpoint.list_models()[0].model+f'@{endpoint.list_models()[0].model_version_id}'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfe9f95-24ee-4a80-af5d-055a062dbfcd",
   "metadata": {},
   "source": [
    "### Review Model Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99ed7230-e41e-4233-ba2c-598835f5be20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'05_05h'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.display_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ef2ca94-ce8f-4baf-b65a-d0105375e9bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/1026793852137/locations/us-central1/models/model_05_05h'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resource_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9a2a979-d1db-4700-a830-abf4671215de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.version_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c403f5f-c1c9-4c00-bf52-05d29ed3626a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run-20220927230247-6'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.version_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27899830-24e4-4d5c-8f2f-fd9918128fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'projects/1026793852137/locations/us-central1/models/model_05_05h@1'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.versioned_resource_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "20c273da-c917-4a08-bd3d-e35bfeff395b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jsonl', 'bigquery', 'csv', 'tf-record', 'tf-record-gzip', 'file-list']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.supported_input_storage_formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ead5efd2-4cd4-45e4-bd45-ee4100f88ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_05_05h'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cad7faa2-0dff-43d5-8735-9d166428c099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://statmike-mlops-349915/05/05h/models/20220927230247/6/model'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "188209f9-9cf9-4bdc-9c44-4fae99c893e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review the model in the Vertex AI Model Registry:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/models/model_05_05h/versions/1/properties?project=statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "print(f'Review the model in the Vertex AI Model Registry:\\nhttps://console.cloud.google.com/vertex-ai/locations/{REGION}/models/{model.name}/versions/{model.version_id}/properties?project={PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0d30bf-b4cb-4147-9dd1-34f4edce01fa",
   "metadata": {},
   "source": [
    "#### Review Model Information Using the `aiplatform_v1` Model Client\n",
    "It may also be helpful to try the [ModelServiceClient](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform_v1.services.model_service.ModelServiceClient) in version 1 of the client to review the model attributes.  Here is example code for trying this.\n",
    "\n",
    "Curious about client versions and layers?  Check out this tip document [aiplatform_notes.md](../Tips/aiplatform_notes.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e2c1ff70-effe-4192-ba1b-d599acf5ba0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"projects/1026793852137/locations/us-central1/models/model_05_05h@1\"\n",
       "display_name: \"05_05h\"\n",
       "predict_schemata {\n",
       "}\n",
       "metadata {\n",
       "}\n",
       "container_spec {\n",
       "  image_uri: \"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-7:latest\"\n",
       "}\n",
       "supported_deployment_resources_types: DEDICATED_RESOURCES\n",
       "supported_deployment_resources_types: SHARED_RESOURCES\n",
       "supported_input_storage_formats: \"jsonl\"\n",
       "supported_input_storage_formats: \"bigquery\"\n",
       "supported_input_storage_formats: \"csv\"\n",
       "supported_input_storage_formats: \"tf-record\"\n",
       "supported_input_storage_formats: \"tf-record-gzip\"\n",
       "supported_input_storage_formats: \"file-list\"\n",
       "supported_output_storage_formats: \"jsonl\"\n",
       "supported_output_storage_formats: \"bigquery\"\n",
       "create_time {\n",
       "  seconds: 1664323764\n",
       "  nanos: 618427000\n",
       "}\n",
       "update_time {\n",
       "  seconds: 1664323768\n",
       "  nanos: 500624000\n",
       "}\n",
       "deployed_models {\n",
       "  endpoint: \"projects/1026793852137/locations/us-central1/endpoints/1961322035766362112\"\n",
       "  deployed_model_id: \"6805735083375329280\"\n",
       "}\n",
       "etag: \"AMEw9yOIT4zwTOutKsVTaTYRSmfpynv-164QtotWu1ACpR6Rwo4UYkGbTqKkVuIds7TH\"\n",
       "labels {\n",
       "  key: \"experiment\"\n",
       "  value: \"05h\"\n",
       "}\n",
       "labels {\n",
       "  key: \"experiment_name\"\n",
       "  value: \"experiment-05-05h-tf-classification-dnn\"\n",
       "}\n",
       "labels {\n",
       "  key: \"run_name\"\n",
       "  value: \"run-20220927230247-6\"\n",
       "}\n",
       "labels {\n",
       "  key: \"series\"\n",
       "  value: \"05\"\n",
       "}\n",
       "supported_export_formats {\n",
       "  id: \"custom-trained\"\n",
       "  exportable_contents: ARTIFACT\n",
       "}\n",
       "artifact_uri: \"gs://statmike-mlops-349915/05/05h/models/20220927230247/6/model\"\n",
       "version_id: \"1\"\n",
       "version_aliases: \"run-20220927230247-6\"\n",
       "version_aliases: \"default\"\n",
       "version_description: \"run-20220927230247-6\"\n",
       "version_create_time {\n",
       "  seconds: 1664323764\n",
       "  nanos: 618427000\n",
       "}\n",
       "version_update_time {\n",
       "  seconds: 1664323768\n",
       "  nanos: 500624000\n",
       "}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.cloud import aiplatform_v1\n",
    "\n",
    "client_options = {\"api_endpoint\": f\"{REGION}-aiplatform.googleapis.com\"}\n",
    "ModelClientv1 = aiplatform_v1.ModelServiceClient(client_options = client_options)\n",
    "\n",
    "ModelClientv1.get_model(\n",
    "    name = model.versioned_resource_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cb37f3-a2b8-42b4-bbee-7ba2e76abb96",
   "metadata": {},
   "source": [
    "---\n",
    "## Retrieve Records For Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "387789b5-8916-4109-a604-e6f91eb1a57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "pred = bq.query(query = f\"SELECT * FROM {BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE} WHERE splits='TEST' LIMIT {n}\").to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "deee9703-813c-45bd-a3e7-ffa2e9a3614e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>splits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35337</td>\n",
       "      <td>1.092844</td>\n",
       "      <td>-0.013230</td>\n",
       "      <td>1.359829</td>\n",
       "      <td>2.731537</td>\n",
       "      <td>-0.707357</td>\n",
       "      <td>0.873837</td>\n",
       "      <td>-0.796130</td>\n",
       "      <td>0.437707</td>\n",
       "      <td>0.396770</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167647</td>\n",
       "      <td>0.027557</td>\n",
       "      <td>0.592115</td>\n",
       "      <td>0.219695</td>\n",
       "      <td>0.036970</td>\n",
       "      <td>0.010984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>a1b10547-d270-48c0-b902-7a0f735dadc7</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60481</td>\n",
       "      <td>1.238973</td>\n",
       "      <td>0.035226</td>\n",
       "      <td>0.063003</td>\n",
       "      <td>0.641406</td>\n",
       "      <td>-0.260893</td>\n",
       "      <td>-0.580097</td>\n",
       "      <td>0.049938</td>\n",
       "      <td>-0.034733</td>\n",
       "      <td>0.405932</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057718</td>\n",
       "      <td>0.104983</td>\n",
       "      <td>0.537987</td>\n",
       "      <td>0.589563</td>\n",
       "      <td>-0.046207</td>\n",
       "      <td>-0.006212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>814c62c8-ade4-47d5-bf83-313b0aafdee5</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>139587</td>\n",
       "      <td>1.870539</td>\n",
       "      <td>0.211079</td>\n",
       "      <td>0.224457</td>\n",
       "      <td>3.889486</td>\n",
       "      <td>-0.380177</td>\n",
       "      <td>0.249799</td>\n",
       "      <td>-0.577133</td>\n",
       "      <td>0.179189</td>\n",
       "      <td>-0.120462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180776</td>\n",
       "      <td>-0.060226</td>\n",
       "      <td>-0.228979</td>\n",
       "      <td>0.080827</td>\n",
       "      <td>0.009868</td>\n",
       "      <td>-0.036997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>d08a1bfa-85c5-4f1b-9537-1c5a93e6afd0</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>162908</td>\n",
       "      <td>-3.368339</td>\n",
       "      <td>-1.980442</td>\n",
       "      <td>0.153645</td>\n",
       "      <td>-0.159795</td>\n",
       "      <td>3.847169</td>\n",
       "      <td>-3.516873</td>\n",
       "      <td>-1.209398</td>\n",
       "      <td>-0.292122</td>\n",
       "      <td>0.760543</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.171627</td>\n",
       "      <td>0.214333</td>\n",
       "      <td>-0.159652</td>\n",
       "      <td>-0.060883</td>\n",
       "      <td>1.294977</td>\n",
       "      <td>0.120503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>802f3307-8e5a-4475-b795-5d5d8d7d0120</td>\n",
       "      <td>TEST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0   35337  1.092844 -0.013230  1.359829  2.731537 -0.707357  0.873837   \n",
       "1   60481  1.238973  0.035226  0.063003  0.641406 -0.260893 -0.580097   \n",
       "2  139587  1.870539  0.211079  0.224457  3.889486 -0.380177  0.249799   \n",
       "3  162908 -3.368339 -1.980442  0.153645 -0.159795  3.847169 -3.516873   \n",
       "\n",
       "         V7        V8        V9  ...       V23       V24       V25       V26  \\\n",
       "0 -0.796130  0.437707  0.396770  ... -0.167647  0.027557  0.592115  0.219695   \n",
       "1  0.049938 -0.034733  0.405932  ... -0.057718  0.104983  0.537987  0.589563   \n",
       "2 -0.577133  0.179189 -0.120462  ...  0.180776 -0.060226 -0.228979  0.080827   \n",
       "3 -1.209398 -0.292122  0.760543  ... -1.171627  0.214333 -0.159652 -0.060883   \n",
       "\n",
       "        V27       V28  Amount  Class                        transaction_id  \\\n",
       "0  0.036970  0.010984     0.0      0  a1b10547-d270-48c0-b902-7a0f735dadc7   \n",
       "1 -0.046207 -0.006212     0.0      0  814c62c8-ade4-47d5-bf83-313b0aafdee5   \n",
       "2  0.009868 -0.036997     0.0      0  d08a1bfa-85c5-4f1b-9537-1c5a93e6afd0   \n",
       "3  1.294977  0.120503     0.0      0  802f3307-8e5a-4475-b795-5d5d8d7d0120   \n",
       "\n",
       "   splits  \n",
       "0    TEST  \n",
       "1    TEST  \n",
       "2    TEST  \n",
       "3    TEST  \n",
       "\n",
       "[4 rows x 33 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd3f889-38d4-47d8-9df8-72b63afa1a72",
   "metadata": {},
   "source": [
    "Remove columns not included as features in the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9932f548-2c04-4150-99e0-0da87e8f216c",
   "metadata": {},
   "outputs": [],
   "source": [
    "newobs = pred[pred.columns[~pred.columns.isin(VAR_OMIT.split()+[VAR_TARGET, 'splits'])]].to_dict(orient='records')\n",
    "#newobs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "74109e3f-fa98-4234-9496-4eb45dbabd90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "50ec56f7-ecff-4ca9-bc00-a552f010280f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Time': 35337,\n",
       " 'V1': 1.0928441854981998,\n",
       " 'V2': -0.0132303486713432,\n",
       " 'V3': 1.35982868199426,\n",
       " 'V4': 2.7315370965921004,\n",
       " 'V5': -0.707357349219652,\n",
       " 'V6': 0.8738370029866129,\n",
       " 'V7': -0.7961301510622031,\n",
       " 'V8': 0.437706509544851,\n",
       " 'V9': 0.39676985012996396,\n",
       " 'V10': 0.587438102569443,\n",
       " 'V11': -0.14979756231827498,\n",
       " 'V12': 0.29514781622888103,\n",
       " 'V13': -1.30382621882143,\n",
       " 'V14': -0.31782283120234495,\n",
       " 'V15': -2.03673231037199,\n",
       " 'V16': 0.376090905274179,\n",
       " 'V17': -0.30040350116459497,\n",
       " 'V18': 0.433799615590844,\n",
       " 'V19': -0.145082264348681,\n",
       " 'V20': -0.240427548108996,\n",
       " 'V21': 0.0376030733329398,\n",
       " 'V22': 0.38002620963091405,\n",
       " 'V23': -0.16764742731151097,\n",
       " 'V24': 0.0275573495476881,\n",
       " 'V25': 0.59211469704354,\n",
       " 'V26': 0.219695164116351,\n",
       " 'V27': 0.0369695108704894,\n",
       " 'V28': 0.010984441006191,\n",
       " 'Amount': 0.0}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newobs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217d221d-e34a-4720-8335-fd529118d10b",
   "metadata": {},
   "source": [
    "---\n",
    "## Create Custom Container For Model Serving\n",
    "\n",
    "Cloud Build will be used to create a custom container with a [tensorflow/serving repository](https://hub.docker.com/r/tensorflow/serving/tags/) image that includes a model.  The resulting image will be stored in Artifact Registry.\n",
    "\n",
    "To learn more about creating custom containers for ML workflows visit the tips notebook [Python Custom Containers](../Tips/Python%20Custom%20Container.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be5cfb9-5f77-4e67-ab76-01ccd101f721",
   "metadata": {},
   "source": [
    "#### Store Resources in Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e8a691f2-fa71-4018-863f-6b0de65cea31",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = gcs.lookup_bucket(PROJECT_ID)\n",
    "SOURCEPATH = f'{SERIES}/{EXPERIMENT}/serving'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2225931e-8611-403c-9cba-f115dd60c910",
   "metadata": {},
   "source": [
    "**Note** In this series of notebooks `05` used the local notebook to train with TensorFlow while the notebooks `05a-i` use a pre-built container with a possibly different version. Knowing these versions may be important to pull the correct image from the tensorflow/serving repository of images.  The example below pulls the imaged tagged `2.7.4` to align with the version of TensorFlow used to train modles in notebooks `05a-i`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "015ddfcb-bc80-4ee1-acbd-1d805800a680",
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_version = '2.7.4'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bae575-b60f-4cd2-b6e8-904cf30e855d",
   "metadata": {},
   "source": [
    "#### Create the Dockerfile\n",
    "A basic dockerfile thats take the base image and copies the model in and define the startup commands to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2051e957-76d4-4c6f-80ea-02b3218615f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dockerfile = f\"\"\"\n",
    "FROM tensorflow/serving:{serving_version}\n",
    "#ENTRYPOINT [“/usr/bin/env”]\n",
    "ENV MODEL_NAME={SERIES}\n",
    "ENV PORT=8501\n",
    "#COPY model/* /models/{SERIES}/1/\n",
    "COPY model /models/{SERIES}/1\n",
    "CMD tensorflow_model_server --port8500 --rest_api_port=$PORT --model_base_path=/models/{SERIES} --model_name=$MODEL_NAME\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6b02f634-f9a7-47c2-a284-ec74d80959a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = bucket.blob(f'{SOURCEPATH}/Dockerfile')\n",
    "blob.upload_from_string(dockerfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6ec084-1fe6-4f8b-b072-41dc746ed421",
   "metadata": {},
   "source": [
    "#### Setup Artifact Registry\n",
    "\n",
    "Artifact registry organizes artifacts with repositories.  Each repository contains packages and is designated to hold a partifcular format of package: Docker images, Python Packages and [others](https://cloud.google.com/artifact-registry/docs/supported-formats#package)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ede75d-000b-4f88-a89f-0952160ef998",
   "metadata": {},
   "source": [
    "##### List Repositories\n",
    "\n",
    "This may be empty if no repositories have been created for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "710ab179-d782-4e69-8437-918756663e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects/statmike-mlops-349915/locations/us-central1/repositories/statmike-mlops-349915\n",
      "projects/statmike-mlops-349915/locations/us-central1/repositories/statmike-mlops-349915-docker\n",
      "projects/statmike-mlops-349915/locations/us-central1/repositories/statmike-mlops-349915-python\n"
     ]
    }
   ],
   "source": [
    "for repo in ar_client.list_repositories(parent = f'projects/{PROJECT_ID}/locations/{REGION}'):\n",
    "    print(repo.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac1f09f-3922-46e9-99ab-4f1ac943b674",
   "metadata": {},
   "source": [
    "#### Create Docker Image Repository\n",
    "\n",
    "Create an Artifact Registry Repository to hold Docker Images created by this notebook.  First, check to see if it is already created by a previous run and retrieve it if it has.  Otherwise, create!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7d2efc61-f790-46b5-84c5-03b478f09edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved existing repo: projects/statmike-mlops-349915/locations/us-central1/repositories/statmike-mlops-349915-docker\n"
     ]
    }
   ],
   "source": [
    "docker_repo = None\n",
    "for repo in ar_client.list_repositories(parent = f'projects/{PROJECT_ID}/locations/{REGION}'):\n",
    "    if f'{PROJECT_ID}-docker' in repo.name:\n",
    "        docker_repo = repo\n",
    "        print(f'Retrieved existing repo: {docker_repo.name}')\n",
    "\n",
    "if not docker_repo:\n",
    "    operation = ar_client.create_repository(\n",
    "        request = artifactregistry_v1.CreateRepositoryRequest(\n",
    "            parent = f'projects/{PROJECT_ID}/locations/{REGION}',\n",
    "            repository_id = f'{PROJECT_ID}-docker',\n",
    "            repository = artifactregistry_v1.Repository(\n",
    "                description = f'A repository for the {EXPERIMENT} experiment that holds docker images.',\n",
    "                name = f'{PROJECT_ID}-docker',\n",
    "                format_ = artifactregistry_v1.Repository.Format.DOCKER,\n",
    "                labels = {'series': SERIES, 'experiment': EXPERIMENT}\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    print('Creating Repository ...')\n",
    "    docker_repo = operation.result()\n",
    "    print(f'Completed creating repo: {docker_repo.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "492d014c-62f3-44b4-a4e8-c0cee308f7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('projects/statmike-mlops-349915/locations/us-central1/repositories/statmike-mlops-349915-docker',\n",
       " 'DOCKER')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docker_repo.name, docker_repo.format_.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d828a942-89c8-4e14-aa95-39580f0a3541",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPOSITORY = f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{docker_repo.name.split('/')[-1]}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cceb24eb-0f01-434a-831f-b313a577ca50",
   "metadata": {},
   "source": [
    "#### Build Custom Container\n",
    "Use the Cloud Build client to construct and run the build instructions.  Here the files collected in GCS are copied to the build instance, then the Docker build in run in the folder with the `Dockerfile`.  The resulting image is pushed to Artifact Registry (setup above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7f4b311b-81e6-46e3-b49e-999ec37b59f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://statmike-mlops-349915/05/05h/models/20220927230247/6/model'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c8497493-1d86-420d-8635-a1b952a04746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the build config with empty list of steps - these will be added sequentially\n",
    "build = cloudbuild_v1.Build(\n",
    "    steps = []\n",
    ")\n",
    "# copy the model - will create folder /model/<contents, like .pb>\n",
    "build.steps.append(\n",
    "    {\n",
    "        'name': 'gcr.io/cloud-builders/gsutil',\n",
    "        'args': ['cp', '-r', f'{model.uri}', '/workspace']\n",
    "    }\n",
    ")\n",
    "# retrieve the Dockerfile\n",
    "build.steps.append(\n",
    "    {\n",
    "        'name': 'gcr.io/cloud-builders/gsutil',\n",
    "        'args': ['cp', '-r', f'gs://{PROJECT_ID}/{SOURCEPATH}/Dockerfile', '/workspace']\n",
    "    }\n",
    ")\n",
    "# docker build\n",
    "build.steps.append(\n",
    "    {\n",
    "        'name': 'gcr.io/cloud-builders/docker',\n",
    "        'args': ['build', '-t', f'{REPOSITORY}/{EXPERIMENT}', '/workspace']\n",
    "    }    \n",
    ")\n",
    "# docker push\n",
    "build.images = [f\"{REPOSITORY}/{EXPERIMENT}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8f5d0782-c3ad-477d-9620-0acc7d5fa6ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "steps {\n",
       "  name: \"gcr.io/cloud-builders/gsutil\"\n",
       "  args: \"cp\"\n",
       "  args: \"-r\"\n",
       "  args: \"gs://statmike-mlops-349915/05/05h/models/20220927230247/6/model\"\n",
       "  args: \"/workspace\"\n",
       "}\n",
       "steps {\n",
       "  name: \"gcr.io/cloud-builders/gsutil\"\n",
       "  args: \"cp\"\n",
       "  args: \"-r\"\n",
       "  args: \"gs://statmike-mlops-349915/05/05_predictions/serving/Dockerfile\"\n",
       "  args: \"/workspace\"\n",
       "}\n",
       "steps {\n",
       "  name: \"gcr.io/cloud-builders/docker\"\n",
       "  args: \"build\"\n",
       "  args: \"-t\"\n",
       "  args: \"us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915-docker/05_predictions\"\n",
       "  args: \"/workspace\"\n",
       "}\n",
       "images: \"us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915-docker/05_predictions\""
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5a3fc01f-84cb-45e1-89f6-01ed35bfc2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "operation = cb_client.create_build(\n",
    "    project_id = PROJECT_ID,\n",
    "    build = build\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c713b2fe-6407-4e71-95fe-4ca2fa8e5aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Status.SUCCESS: 3>,\n",
       " images: \"us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915-docker/05_predictions\")"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = operation.result()\n",
    "response.status, response.artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "611d18a4-f98e-4a0e-9db5-24e4166fe026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review the Custom Container with Artifact Registry in the Google Cloud Console:\n",
      "https://console.cloud.google.com/artifacts/docker/statmike-mlops-349915/us-central1/statmike-mlops-349915-docker?project=statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "print(f\"Review the Custom Container with Artifact Registry in the Google Cloud Console:\\nhttps://console.cloud.google.com/artifacts/docker/{PROJECT_ID}/{REGION}/{PROJECT_ID}-docker?project={PROJECT_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1fc2d7-177c-4e97-9d16-994d9e36f238",
   "metadata": {},
   "source": [
    "---\n",
    "## Cloud Run: TensorFlow ModelSever\n",
    "\n",
    "Cloud Run will be used to host our custom container and handle prediction requests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8c8d54-10d6-4cf8-b6bd-63c6f763ec83",
   "metadata": {},
   "source": [
    "### Deploy as Cloud Run Service\n",
    "This demonstration creates an open service allowing all traffic.  Review documentation for [Cloud Run](https://cloud.google.com/run/docs/overview/what-is-cloud-run) and the [CLOUD SKD CLI sections](https://cloud.google.com/sdk/gcloud/reference/run) for `gcloud run`.\n",
    "\n",
    "\n",
    "If you have a policy inforced for 'Domain Restricted Sharing' then it may need adjusting for the project to allow this.  This should be done with care and you may wish to only accept authenticated or internal traffic.  Review options for authentication [here](https://cloud.google.com/run/docs/authenticating/overview).\n",
    "\n",
    "Updated Org Policy:\n",
    "- Logged in as Admin\n",
    "- IAM > Organization Policies\n",
    "    - Changed to Project (not org level)\n",
    "    - Filter 'Domain Restricted Sharing'\n",
    "    - Select and Edit\n",
    "        - Applies to = Customize\n",
    "        - Policy enforcement = Replace\n",
    "        - Rules = Allow all\n",
    "    - Save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffe3070-96bb-49db-9959-7885215c91fa",
   "metadata": {},
   "source": [
    "View the Cloud Run Console for this project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d669cd1f-3e84-4182-bf8d-a04c548a2d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://console.cloud.google.com/run?project=statmike-mlops-349915\n"
     ]
    }
   ],
   "source": [
    "print(f'https://console.cloud.google.com/run?project={PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08695594-e59b-48fe-b10d-61aa0e8731e5",
   "metadata": {},
   "source": [
    "Create the Cloud Run Service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "42bc027b-a6c4-406e-ae53-101e3e048726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying new service...                                                       \n",
      "  . Creating Revision...                                                       \n",
      "  . Routing traffic...                                                         \n",
      "  . Setting IAM Policy...                                                      \n"
     ]
    }
   ],
   "source": [
    "!gcloud run deploy endpoint-$SERIES --image=$REPOSITORY/$EXPERIMENT --port=8501 --region=$REGION --platform=managed --allow-unauthenticated --no-user-output-enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b585f512-c92f-462f-b429-dd56da9ad084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SERVICE      REGION       URL                                          LAST DEPLOYED BY                                     LAST DEPLOYED AT\n",
      "\u001b[32m✔\u001b[39;0m  endpoint-05  us-central1  https://endpoint-05-urlxi72dpa-uc.a.run.app  1026793852137-compute@developer.gserviceaccount.com  2022-09-30T15:51:30.142570Z\n"
     ]
    }
   ],
   "source": [
    "!gcloud run services list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e1f6a326-7443-4f5e-b2b4-539b632b68ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://endpoint-05-urlxi72dpa-uc.a.run.app'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "services = !gcloud run services list --format=\"json\" --filter=SERVICE:endpoint-$SERIES\n",
    "services = json.loads(\"\".join(services))[0]\n",
    "services['status']['url']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49de52b9-eb6b-49d2-829e-55de2e2cc157",
   "metadata": {},
   "source": [
    "If you had to adjust a `Domain Restricted Sharing` policy after deployment then this command can update the service to allow all traffic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "30e425d9-e609-4146-8df8-db01f403db11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!gcloud run services add-iam-policy-binding --region=us-central1 --member='allUsers' --role=roles/run.invoker endpoint-$SERIES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1ab4d5-3f2d-4d74-8760-da5a41e992b8",
   "metadata": {},
   "source": [
    "### Get Predictions Using Cloud Run Service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4c8024-df32-426a-823d-fcb9a3300e84",
   "metadata": {},
   "source": [
    "Prepare in instance (observation) for prediction request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "785797f2-878f-44b3-adb4-e612710d3966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"instances\": [{\"Time\": 35337, \"V1\": 1.0928441854981998, \"V2\": -0.0132303486713432, \"V3\": 1.35982868199426, \"V4\": 2.7315370965921004, \"V5\": -0.707357349219652, \"V6\": 0.8738370029866129, \"V7\": -0.7961301510622031, \"V8\": 0.437706509544851, \"V9\": 0.39676985012996396, \"V10\": 0.587438102569443, \"V11\": -0.14979756231827498, \"V12\": 0.29514781622888103, \"V13\": -1.30382621882143, \"V14\": -0.31782283120234495, \"V15\": -2.03673231037199, \"V16\": 0.376090905274179, \"V17\": -0.30040350116459497, \"V18\": 0.433799615590844, \"V19\": -0.145082264348681, \"V20\": -0.240427548108996, \"V21\": 0.0376030733329398, \"V22\": 0.38002620963091405, \"V23\": -0.16764742731151097, \"V24\": 0.0275573495476881, \"V25\": 0.59211469704354, \"V26\": 0.219695164116351, \"V27\": 0.0369695108704894, \"V28\": 0.010984441006191, \"Amount\": 0.0}]}'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tryob_json = json.dumps({\"instances\": [newobs[0]]})\n",
    "tryob_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6ba5ee-bee6-43ba-99c4-8413a98307f3",
   "metadata": {},
   "source": [
    "Make prediction request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "660c200b-4869-4ead-b8d6-1be11f13285a",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_response = requests.post(f\"{services['status']['url']}/v1/models/{SERIES}:predict\", data=tryob_json, headers={\"content-type\": \"application/json\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "30624f96-a7ef-46e6-8058-842ee96dcd4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "cc897f00-ffc5-4730-8930-557185568f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"predictions\": [[0.999359429, 0.000640570885]\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "8ddb4769-4ae9-474d-8aaa-78ce9480a502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.999359429, 0.000640570885]]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = json.loads(json_response.text)['predictions']\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "262240e2-582b-48a3-a673-2ce639d6e0ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c920b479-87b0-484e-a0cf-25479280a166",
   "metadata": {},
   "source": [
    "### Remove Service\n",
    "This command will remove the service.\n",
    "\n",
    "Alternatively, you could adjust the service to not accept traffic.  Cloud Run will scale down to zero - or only charge when CPU is used (startup, shutdown, and receiving requests) unless `--no-cpu-throttling` is used ([documentation](https://cloud.google.com/run/docs/configuring/cpu-allocation#setting))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "37283448-b36c-49a5-9b0b-f93d741df84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting [endpoint-05]...done.                                                 \n",
      "Deleted service [endpoint-05].\n"
     ]
    }
   ],
   "source": [
    "!gcloud run services delete --region=us-central1 --quiet endpoint-$SERIES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643ac692-dc97-4133-ae18-0cd48a02259a",
   "metadata": {},
   "source": [
    "---\n",
    "## Local (to Notebook): TensorFlow Model Server\n",
    "\n",
    "The local notebook environment may have docker installed. For example, Vertex AI Workbench user-managed instances do have docker installed.  In this case the custom container in Artfact Registry created above can be pulled (`docker pull`) and run (`docker run`) here to serve prediction requests from the local compute instance.  This can be great for testing, troubleshooting, or doing local experiments. It can also potentially be helpful when you need to try various prediction requests scenarios for interpretation/explainability like is done in these notebooks:\n",
    "- [05Tools - Interpretability with LIT.ipynb](./05Tools%20-%20Interpretability%20with%20LIT.ipynb)\n",
    "- [05Tools - Interpretability with WIT.ipynb](./05Tools%20-%20Interpretability%20with%20WIT.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecde395f-1d85-4dc1-8261-276b5c0ff808",
   "metadata": {},
   "source": [
    "### Pull the custom serving image locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ca610a5d-4a83-420b-a2c6-9a156ea135c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default tag: latest\n",
      "latest: Pulling from statmike-mlops-349915/statmike-mlops-349915-docker/05_predictions\n",
      "\n",
      "\u001b[1B8a513d66: Already exists \n",
      "\u001b[1B803b7168: Already exists \n",
      "\u001b[1B227c53ba: Already exists \n",
      "\u001b[1B6b95623a: Already exists \n",
      "\u001b[1B8a441e9f: Already exists \n",
      "\u001b[1BDigest: sha256:dcb92088379de27cd1d32a8981eb2b2c4998a52af77a00341366d654bf1ea69b\n",
      "Status: Downloaded newer image for us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915-docker/05_predictions:latest\n",
      "us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915-docker/05_predictions:latest\n"
     ]
    }
   ],
   "source": [
    "!docker pull $REPOSITORY/$EXPERIMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdb5d35-5f71-4540-b8c4-423036fb9c82",
   "metadata": {},
   "source": [
    "### Run the serving image locally\n",
    "\n",
    "The container is going to be run with commands in this notebook.  In order to run the serving while not tying up further exectutions in this notebook, a subprocess will be launched using `multiprocessing`. To learn more about multiprocessing and running tasks from Python in parallel visit the tips notebook [Python Multiprocessing](../Tips/Python%20Multiprocessing.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95960c0f-ed49-41de-8a38-45b872d3b111",
   "metadata": {},
   "source": [
    "First, build the syntax of the `docker run` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "60608520-66cd-445f-8fd1-869bac4dbe11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker run -t --rm -p 8501:8501 us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915-docker/05_predictions\n"
     ]
    }
   ],
   "source": [
    "command = f'''docker run -t --rm -p 8501:8501 {REPOSITORY}/{EXPERIMENT}'''\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46422912-69a2-4d26-85b6-d8dfb21a478b",
   "metadata": {},
   "source": [
    "Run the command in a subprocess at the local folder of this notebook - use multiprocess.Process():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "4644a43e-fb05-4444-8365-76f6ea927da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown argument: /bin/sh\n",
      "usage: tensorflow_model_server\n",
      "Flags:\n",
      "\t--port=8500                      \tint32\tTCP port to listen on for gRPC/HTTP API. Disabled if port set to zero.\n",
      "\t--grpc_socket_path=\"\"            \tstring\tIf non-empty, listen to a UNIX socket for gRPC API on the given path. Can be either relative or absolute path.\n",
      "\t--rest_api_port=0                \tint32\tPort to listen on for HTTP/REST API. If set to zero HTTP/REST API will not be exported. This port must be different than the one specified in --port.\n",
      "\t--rest_api_num_threads=16        \tint32\tNumber of threads for HTTP/REST API processing. If not set, will be auto set based on number of CPUs.\n",
      "\t--rest_api_timeout_in_ms=30000   \tint32\tTimeout for HTTP/REST API calls.\n",
      "\t--rest_api_enable_cors_support=false\tbool\tEnable CORS headers in response\n",
      "\t--enable_batching=false          \tbool\tenable batching\n",
      "\t--allow_version_labels_for_unavailable_models=false\tbool\tIf true, allows assigning unused version labels to models that are not available yet.\n",
      "\t--batching_parameters_file=\"\"    \tstring\tIf non-empty, read an ascii BatchingParameters protobuf from the supplied file name and use the contained values instead of the defaults.\n",
      "\t--model_config_file=\"\"           \tstring\tIf non-empty, read an ascii ModelServerConfig protobuf from the supplied file name, and serve the models in that file. This config file can be used to specify multiple models to serve and other advanced parameters including non-default version policy. (If used, --model_name, --model_base_path are ignored.)\n",
      "\t--model_config_file_poll_wait_seconds=0\tint32\tInterval in seconds between each poll of the filesystemfor model_config_file. If unset or set to zero, poll will be done exactly once and not periodically. Setting this to negative is reserved for testing purposes only.\n",
      "\t--model_name=\"default\"           \tstring\tname of model (ignored if --model_config_file flag is set)\n",
      "\t--model_base_path=\"\"             \tstring\tpath to export (ignored if --model_config_file flag is set, otherwise required)\n",
      "\t--num_load_threads=0             \tint32\tThe number of threads in the thread-pool used to load servables. If set as 0, we don't use a thread-pool, and servable loads are performed serially in the manager's main work loop, may casue the Serving request to be delayed. Default: 0\n",
      "\t--num_unload_threads=0           \tint32\tThe number of threads in the thread-pool used to unload servables. If set as 0, we don't use a thread-pool, and servable loads are performed serially in the manager's main work loop, may casue the Serving request to be delayed. Default: 0\n",
      "\t--max_num_load_retries=5         \tint32\tmaximum number of times it retries loading a model after the first failure, before giving up. If set to 0, a load is attempted only once. Default: 5\n",
      "\t--load_retry_interval_micros=60000000\tint64\tThe interval, in microseconds, between each servable load retry. If set negative, it doesn't wait. Default: 1 minute\n",
      "\t--file_system_poll_wait_seconds=1\tint32\tInterval in seconds between each poll of the filesystem for new model version. If set to zero poll will be exactly done once and not periodically. Setting this to negative value will disable polling entirely causing ModelServer to indefinitely wait for a new model at startup. Negative values are reserved for testing purposes only.\n",
      "\t--flush_filesystem_caches=true   \tbool\tIf true (the default), filesystem caches will be flushed after the initial load of all servables, and after each subsequent individual servable reload (if the number of load threads is 1). This reduces memory consumption of the model server, at the potential cost of cache misses if model files are accessed after servables are loaded.\n",
      "\t--tensorflow_session_parallelism=0\tint64\tNumber of threads to use for running a Tensorflow session. Auto-configured by default.Note that this option is ignored if --platform_config_file is non-empty.\n",
      "\t--tensorflow_intra_op_parallelism=0\tint64\tNumber of threads to use to parallelize the executionof an individual op. Auto-configured by default.Note that this option is ignored if --platform_config_file is non-empty.\n",
      "\t--tensorflow_inter_op_parallelism=0\tint64\tControls the number of operators that can be executed simultaneously. Auto-configured by default.Note that this option is ignored if --platform_config_file is non-empty.\n",
      "\t--use_alts_credentials=false     \tbool\tUse Google ALTS credentials\n",
      "\t--ssl_config_file=\"\"             \tstring\tIf non-empty, read an ascii SSLConfig protobuf from the supplied file name and set up a secure gRPC channel\n",
      "\t--platform_config_file=\"\"        \tstring\tIf non-empty, read an ascii PlatformConfigMap protobuf from the supplied file name, and use that platform config instead of the Tensorflow platform. (If used, --enable_batching is ignored.)\n",
      "\t--per_process_gpu_memory_fraction=0.000000\tfloat\tFraction that each process occupies of the GPU memory space the value is between 0.0 and 1.0 (with 0.0 as the default) If 1.0, the server will allocate all the memory when the server starts, If 0.0, Tensorflow will automatically select a value.\n",
      "\t--saved_model_tags=\"serve\"       \tstring\tComma-separated set of tags corresponding to the meta graph def to load from SavedModel.\n",
      "\t--grpc_channel_arguments=\"\"      \tstring\tA comma separated list of arguments to be passed to the grpc server. (e.g. grpc.max_connection_age_ms=2000)\n",
      "\t--grpc_max_threads=16            \tint32\tMax grpc server threads to handle grpc messages.\n",
      "\t--enable_model_warmup=true       \tbool\tEnables model warmup, which triggers lazy initializations (such as TF optimizations) at load time, to reduce first request latency.\n",
      "\t--version=false                  \tbool\tDisplay version\n",
      "\t--monitoring_config_file=\"\"      \tstring\tIf non-empty, read an ascii MonitoringConfig protobuf from the supplied file name\n",
      "\t--remove_unused_fields_from_bundle_metagraph=true\tbool\tRemoves unused fields from MetaGraphDef proto message to save memory.\n",
      "\t--prefer_tflite_model=false      \tbool\tEXPERIMENTAL; CAN BE REMOVED ANYTIME! Prefer TensorFlow Lite model from `model.tflite` file in SavedModel directory, instead of the TensorFlow model from `saved_model.pb` file. If no TensorFlow Lite model found, fallback to TensorFlow model.\n",
      "\t--num_tflite_pools=4             \tint32\tEXPERIMENTAL; CAN BE REMOVED ANYTIME! Number of TFLite interpreters in an interpreter pool of TfLiteSession. Typically there is one TfLiteSession for each TF Lite model that is loaded. If not set, will be auto set based on number of CPUs.\n",
      "\t--num_tflite_interpreters_per_pool=1\tint32\tEXPERIMENTAL; CAN BE REMOVED ANYTIME! Number of TFLite interpreters in an interpreter pool of TfLiteSession. Typically there is one TfLiteSession for each TF Lite model that is loaded. If not set, will be 1.\n",
      "\t--enable_signature_method_name_check=false\tbool\tEnable method_name check for SignatureDef. Disable this if serving native TF2 regression/classification models.\n",
      "\t--xla_cpu_compilation_enabled=false\tbool\tEXPERIMENTAL; CAN BE REMOVED ANYTIME! Enable XLA:CPU JIT (default is disabled). With XLA:CPU JIT disabled, models utilizing this feature will return bad Status on first compilation request.\n",
      "\t--enable_profiler=true           \tbool\tEnable profiler service.\n",
      "\t--thread_pool_factory_config_file=\"\"\tstring\tIf non-empty, read an ascii ThreadPoolConfig protobuf from the supplied file name.\n",
      "2022-09-30 15:33:02.443289: I tensorflow_serving/model_servers/server.cc:89] Building single TensorFlow model file config:  model_name: 05 model_base_path: /models/05\n",
      "2022-09-30 15:33:02.443668: I tensorflow_serving/model_servers/server_core.cc:465] Adding/updating models.\n",
      "2022-09-30 15:33:02.443704: I tensorflow_serving/model_servers/server_core.cc:591]  (Re-)adding model: 05\n",
      "2022-09-30 15:33:02.544413: I tensorflow_serving/core/basic_manager.cc:740] Successfully reserved resources to load servable {name: 05 version: 1}\n",
      "2022-09-30 15:33:02.544463: I tensorflow_serving/core/loader_harness.cc:66] Approving load for servable version {name: 05 version: 1}\n",
      "2022-09-30 15:33:02.544479: I tensorflow_serving/core/loader_harness.cc:74] Loading servable version {name: 05 version: 1}\n",
      "2022-09-30 15:33:02.544560: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /models/05/1\n",
      "2022-09-30 15:33:02.559722: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2022-09-30 15:33:02.559788: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: /models/05/1\n",
      "2022-09-30 15:33:02.559992: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-30 15:33:02.649560: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2022-09-30 15:33:02.779244: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /models/05/1\n",
      "2022-09-30 15:33:02.856206: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 311641 microseconds.\n",
      "2022-09-30 15:33:02.860766: I tensorflow_serving/servables/tensorflow/saved_model_warmup_util.cc:59] No warmup data file found at /models/05/1/assets.extra/tf_serving_warmup_requests\n",
      "2022-09-30 15:33:02.864534: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: 05 version: 1}\n",
      "2022-09-30 15:33:02.865664: I tensorflow_serving/model_servers/server_core.cc:486] Finished adding/updating models\n",
      "2022-09-30 15:33:02.865819: I tensorflow_serving/model_servers/server.cc:133] Using InsecureServerCredentials\n",
      "2022-09-30 15:33:02.865866: I tensorflow_serving/model_servers/server.cc:383] Profiler service is enabled\n",
      "2022-09-30 15:33:02.867702: I tensorflow_serving/model_servers/server.cc:409] Running gRPC ModelServer at 0.0.0.0:8500 ...\n",
      "[warn] getaddrinfo: address family for nodename not supported\n",
      "2022-09-30 15:33:02.870659: I tensorflow_serving/model_servers/server.cc:430] Exporting HTTP/REST API at:localhost:8501 ...\n",
      "[evhttp_server.cc : 245] NET_LOG: Entering the event loop ...\n"
     ]
    }
   ],
   "source": [
    "def docker_runner():\n",
    "    !{command}\n",
    "    #!docker run -t -p 8501:8501 -v \"/$(pwd)/temp/05_predictions/model:/models/05/01\" -e MODEL_NAME=05 tensorflow/serving:2.7.4\n",
    "\n",
    "def main():\n",
    "    p = multiprocessing.Process(target=docker_runner)\n",
    "    p.start()\n",
    "    return p\n",
    "    \n",
    "p = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa361735-fd83-43e6-862b-394e2f1f3474",
   "metadata": {},
   "source": [
    "### Get Predictions on Exposed Port"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a75630d-75b8-4da1-9a79-5bcb41a014fb",
   "metadata": {},
   "source": [
    "Prepare in instance (observation) for prediction request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "289c6135-3def-4de5-95c5-ea1cba601586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"instances\": [{\"Time\": 35337, \"V1\": 1.0928441854981998, \"V2\": -0.0132303486713432, \"V3\": 1.35982868199426, \"V4\": 2.7315370965921004, \"V5\": -0.707357349219652, \"V6\": 0.8738370029866129, \"V7\": -0.7961301510622031, \"V8\": 0.437706509544851, \"V9\": 0.39676985012996396, \"V10\": 0.587438102569443, \"V11\": -0.14979756231827498, \"V12\": 0.29514781622888103, \"V13\": -1.30382621882143, \"V14\": -0.31782283120234495, \"V15\": -2.03673231037199, \"V16\": 0.376090905274179, \"V17\": -0.30040350116459497, \"V18\": 0.433799615590844, \"V19\": -0.145082264348681, \"V20\": -0.240427548108996, \"V21\": 0.0376030733329398, \"V22\": 0.38002620963091405, \"V23\": -0.16764742731151097, \"V24\": 0.0275573495476881, \"V25\": 0.59211469704354, \"V26\": 0.219695164116351, \"V27\": 0.0369695108704894, \"V28\": 0.010984441006191, \"Amount\": 0.0}]}'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tryob_json = json.dumps({\"instances\": [newobs[0]]})\n",
    "tryob_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4b9ac9-a9a5-42e1-8ad1-6f350b002fc9",
   "metadata": {},
   "source": [
    "Make prediction request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4f0cc7b0-84c4-42ed-a189-edf0b640e691",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_response = requests.post(f'http://localhost:8501/v1/models/{SERIES}:predict', data=tryob_json, headers={\"content-type\": \"application/json\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "065d999a-80ca-4b39-a4ae-ea6c261b1fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c1ed75b7-7fe6-4aea-9c59-81367a76523c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"predictions\": [[0.999359429, 0.000640570885]\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ff377499-4598-4b40-b462-1bee83be43da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.999359429, 0.000640570885]]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = json.loads(json_response.text)['predictions']\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "3281b081-b717-421e-9cfa-beb06f75c452",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b8cd3f-d9eb-4b3e-b3e1-07bd26b9edc2",
   "metadata": {},
   "source": [
    "### Shutdown TensorFlow Serving Container\n",
    "There are two entities running: a subprocess called `p` and a docker container that was run by the subprocess.  It is not enough to just stop `p` but it might be enough to stop the container and then the subprocess will terminate due to completion.  The command below stop the subprocess `p` and then stop and remove the container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "aad03bc4-7285-4110-94bd-3e1baf0e6ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "329d9b95-fdbd-4a65-920f-4735bc034bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.is_alive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2aeb3c1c-2c98-4399-8f5d-d444bbb21f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CONTAINER ID   IMAGE                                                                                          COMMAND                  CREATED              STATUS              PORTS                              NAMES',\n",
       " '14f0a2c5442c   us-central1-docker.pkg.dev/statmike-mlops-349915/statmike-mlops-349915-docker/05_predictions   \"/usr/bin/tf_serving…\"   About a minute ago   Up About a minute   8500/tcp, 0.0.0.0:8501->8501/tcp   clever_stonebraker',\n",
       " 'cfc6fa1ae606   gcr.io/inverting-proxy/agent                                                                   \"/bin/sh -c \\'/opt/bi…\"   6 weeks ago          Up 3 days                                              proxy-agent']"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docker = !docker ps -a\n",
    "docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5e74dfb8-2417-4c53-92a7-817a9d7a72a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clever_stonebraker\n",
      "clever_stonebraker\n",
      "Error: No such container: 14f0a2c5442c\n"
     ]
    }
   ],
   "source": [
    "for d in docker:\n",
    "    if f'{REPOSITORY}/{EXPERIMENT}' in d:\n",
    "        print(d.split()[-1])\n",
    "        !docker stop {d.split()[-1]}\n",
    "        !docker rm {d.split()[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "01c425d6-b4fe-4ea2-96f0-18c93a8bd0b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE                          COMMAND                  CREATED       STATUS      PORTS     NAMES\n",
      "cfc6fa1ae606   gcr.io/inverting-proxy/agent   \"/bin/sh -c '/opt/bi…\"   6 weeks ago   Up 3 days             proxy-agent\n"
     ]
    }
   ],
   "source": [
    "!docker ps -a"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-3.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m94"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
