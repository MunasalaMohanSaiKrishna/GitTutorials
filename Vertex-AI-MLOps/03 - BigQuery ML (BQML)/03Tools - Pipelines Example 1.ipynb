{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b59f1fb-5557-4f89-9ee6-505e1ccc8509",
   "metadata": {},
   "source": [
    "# 03Tools - Pipeline Example 1\n",
    "\n",
    "**Deploying the current best model to an endpoint**\n",
    "\n",
    "The notebooks `03a` through `03f` all train ML models with different techniques using the same training data.  This might represent:\n",
    "- multiple coworkers working on the same project or\n",
    "- different approaches being tried at different times\n",
    "- continuous development of multiple techniques in parallel\n",
    "\n",
    "In each attempt, the final model is registered to Vertex AI Model Registry as the latest, best attempt for the approach.  All of the model are registered with the same label value for `series`.  Using this label, we could routinely review all the approaches and pick the \"current\" best model for the domain.\n",
    "\n",
    "An example workflow might be:\n",
    "\n",
    "- Candidate selection path:\n",
    "    - Get list of candidate models: Vertex AI Model Registry where labels.series={SERIES} and version_alias=default\n",
    "    - Loop (async) over list of candidate models\n",
    "        - Gather Evaluation: log metrics: evaluation, confusion matrix, ROC curve\n",
    "    - Pick the best candidate model\n",
    "- Current model review path:\n",
    "    - Check for endpoint, create if needed\n",
    "    - Get the deployed model with most traffic \n",
    "    - Condition: if there is a deployed model\n",
    "        - Gather Evaluation: log metrics: evaluation, confusion matrix, ROC curve\n",
    "    - Condition: if there is not a deployed model\n",
    "        - deploy best on endpoint\n",
    "- Compare And update Path:\n",
    "    - Condition: if best > deployed\n",
    "        - deploy best on endpoint\n",
    "\n",
    "In this notebook, this outline will be turned into a Vertex AI Pipeline!\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img alt=\"Pipeline Dashboard\" src=\"../architectures/notebooks/03/pipeline_ex1.png\" width=\"45%\">\n",
    "</p>\n",
    "\n",
    "**Pipelines**\n",
    "When the workflow includes multiple steps with direct dependicies we have a pipeline.  Using Vertex AI Pipelines we can do all these steps in a single serverless manner.  Each of the steps of our workflow outlined above turn into components.  The components are connected through inputs and outputs.  \n",
    "\n",
    "**Prerequisites:**\n",
    "-  One or More of `03a`, `03b`, `03c`, `03d`, `03e`, `03f`\n",
    "    - Each of these register a model/version in the Vertex AI Model Registry\n",
    "\n",
    "**Resources:**\n",
    "- Pipelines:\n",
    "    - [Vertex AI Pipelines](https://cloud.google.com/vertex-ai/docs/pipelines/introduction)\n",
    "        - [Kubeflow](https://www.kubeflow.org/docs/components/pipelines/v2/author-a-pipeline/)\n",
    "            - [Install the Kubeflow Pipelines SDK](https://www.kubeflow.org/docs/components/pipelines/v1/sdk/install-sdk/)\n",
    "        - [Google Cloud Pre-Built Pipeline Components](https://cloud.google.com/vertex-ai/docs/pipelines/gcpc-list)\n",
    "            - [SDK Reference](https://google-cloud-pipeline-components.readthedocs.io)\n",
    "- [BigQuery](https://cloud.google.com/bigquery)\n",
    "    - [Documentation:](https://cloud.google.com/bigquery/docs/query-overview)\n",
    "    - [API:](https://cloud.google.com/bigquery/docs/reference/libraries-overview)\n",
    "        - [Clients](https://cloud.google.com/bigquery/docs/reference/libraries)\n",
    "            - [Python SDK:](https://github.com/googleapis/python-bigquery)\n",
    "            - [Python Library Reference:](https://cloud.google.com/python/docs/reference/bigquery/latest)\n",
    "- [Vertex AI](https://cloud.google.com/vertex-ai)\n",
    "    - [Documentation:](https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform)\n",
    "    - [API:](https://cloud.google.com/vertex-ai/docs/reference)\n",
    "        - [Clients:](https://cloud.google.com/vertex-ai/docs/start/client-libraries)\n",
    "            - [Python SDK:](https://github.com/googleapis/python-aiplatform)\n",
    "            - [Python Library Reference:](https://cloud.google.com/python/docs/reference/aiplatform/latest)\n",
    "\n",
    "\n",
    "**Conceptual Flow & Workflow**\n",
    "<p align=\"center\">\n",
    "  <img alt=\"Conceptual Flow\" src=\"../architectures/slides/03tools_pipe1_arch.png\" width=\"45%\">\n",
    "&nbsp; &nbsp; &nbsp; &nbsp;\n",
    "  <img alt=\"Workflow\" src=\"../architectures/slides/03tools_pipe1_console.png\" width=\"45%\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39de3982-2555-4d5c-bae6-8e7d35710557",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f870ab11-b5dc-4378-830c-b39feaaa5384",
   "metadata": {},
   "source": [
    "inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de005cc5-f141-4593-9f00-6d4da186424f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb73f2d6-e658-445c-8a2a-3c65edfe423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "EXPERIMENT = '03_pipeline_ex1'\n",
    "SERIES = '03'\n",
    "\n",
    "# source data\n",
    "BQ_PROJECT = PROJECT_ID\n",
    "BQ_DATASET = 'fraud'\n",
    "BQ_TABLE = 'fraud_prepped'\n",
    "\n",
    "# Model Training\n",
    "VAR_TARGET = 'Class'\n",
    "VAR_OMIT = 'transaction_id' # add more variables to the string with space delimiters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc1e984-dcde-4348-a72a-6848ac2a7538",
   "metadata": {},
   "source": [
    "packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "968c1a4a-512f-4553-8e8c-130df1100a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from google.cloud import bigquery\n",
    "from datetime import datetime\n",
    "\n",
    "from datetime import datetime\n",
    "from typing import NamedTuple\n",
    "\n",
    "from kfp import dsl\n",
    "from kfp.v2 import dsl as dsl2\n",
    "from kfp.v2 import compiler\n",
    "from kfp.v2.dsl import Artifact, Input, Metrics, ClassificationMetrics, HTML, Output, component"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216f8e48-531b-45b3-ad29-b64557cab774",
   "metadata": {},
   "source": [
    "clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbd2df68-d747-45e7-9448-ec9454508407",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "bq = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f01eff3-dd34-4842-b477-bd9d72314a8c",
   "metadata": {},
   "source": [
    "parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4ca5abe-d716-4376-b7e7-9a8b6f8d45e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "BUCKET = PROJECT_ID\n",
    "URI = f\"gs://{BUCKET}/{SERIES}/{EXPERIMENT}/pipelines\"\n",
    "DIR = f\"temp/{EXPERIMENT}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94bd031b-f214-418b-b5b9-4e6497621956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1026793852137-compute@developer.gserviceaccount.com'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SERVICE_ACCOUNT = !gcloud config list --format='value(core.account)' \n",
    "SERVICE_ACCOUNT = SERVICE_ACCOUNT[0]\n",
    "SERVICE_ACCOUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fed662-28ee-4348-aad1-b4aecd942a21",
   "metadata": {},
   "source": [
    "List the service accounts current roles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "366d859b-84bd-412c-8b52-22a8aca7af55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROLE\n",
      "roles/bigquery.admin\n",
      "roles/owner\n",
      "roles/run.admin\n",
      "roles/storage.objectAdmin\n"
     ]
    }
   ],
   "source": [
    "!gcloud projects get-iam-policy $PROJECT_ID --filter=\"bindings.members:$SERVICE_ACCOUNT\" --format='table(bindings.role)' --flatten=\"bindings[].members\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29145297-e1c9-4667-97e7-5213cc3850de",
   "metadata": {},
   "source": [
    ">Note: If the resulting list is missing [roles/storage.objectAdmin](https://cloud.google.com/storage/docs/access-control/iam-roles) then [revisit the setup notebook](../00%20-%20Setup/00%20-%20Environment%20Setup.ipynb#permissions) and add this permission to the service account with the provided instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f1d92b-35ec-4925-8aa2-e63a0dd84267",
   "metadata": {},
   "source": [
    "environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91e41643-6611-41dc-9519-ac0b129457d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {DIR}\n",
    "!mkdir -p {DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc790f5f-1805-4d09-90c9-a05f632f8571",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02a43fa-c7a1-4336-91d1-d6d17a523513",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "This section follows the process I take to build a workflow as a Vertex AI Pipeline.  \n",
    "1. Create an outline of the workflow\n",
    "2. Prepare components, custom or prebuilt for each step\n",
    "3. Define the pipeline\n",
    "4. Compile and run the pipeline\n",
    "\n",
    "The build process can be iterative where 2, 3, and 4 and created and tested as iterative steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6d632c-8f90-455e-a207-d46ad0100eb4",
   "metadata": {},
   "source": [
    "### 1 - Outline Pipeline\n",
    "\n",
    "Write down in words the flow you want to achieve along with any conditional elements:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b979a503-704f-4fd7-8aa8-cb95796d8807",
   "metadata": {},
   "source": [
    "- Candidate selection path:\n",
    "    - Get list of candidate models: Vertex AI Model Registry where labels.series={SERIES} and version_alias=default\n",
    "    - Loop (async) over list of candidate models\n",
    "        - Gather Evaluation: log metrics: evaluation, confusion matrix, ROC curve\n",
    "    - Pick the best candidate model\n",
    "- Current model review path:\n",
    "    - Check for endpoint, create if needed\n",
    "    - Get the deployed model with most traffic \n",
    "    - Condition: if there is a deployed model\n",
    "        - Gather Evaluation: log metrics: evaluation, confusion matrix, ROC curve\n",
    "    - Condition: if there is not a deployed model\n",
    "        - deploy best on endpoint\n",
    "- Compare And update Path:\n",
    "    - Condition: if best > deployed\n",
    "        - deploy best on endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965a9a23-2cab-45bc-b60f-8699a0ee0d5f",
   "metadata": {},
   "source": [
    "### 2 - Prepare Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045ee8ed-a458-4f7d-9be5-d56a4c46d9bc",
   "metadata": {},
   "source": [
    "#### Component: list_series_models\n",
    "Get a list of BQML model names that are registred in the Vertex AI Model Registry for the Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "694cc82a-ff9b-44a9-90d6-d9388117a858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from kfp.v2.dsl import Artifact, Input, Metrics, Output, component\n",
    "@component(\n",
    "    base_image = \"python:3.9\",\n",
    "    packages_to_install = [\"google-cloud-aiplatform\"]\n",
    ")\n",
    "def list_series_models(\n",
    "    project: str,\n",
    "    region: str,\n",
    "    series: str\n",
    ") -> NamedTuple('outputs', [('candidates', list)]):\n",
    "\n",
    "    # setup\n",
    "    from collections import namedtuple\n",
    "    result = namedtuple('outputs', ['candidates'])\n",
    "    \n",
    "    from google.cloud import aiplatform\n",
    "    aiplatform.init(project = project, location = region)\n",
    "    \n",
    "    # get list of candidate models for series\n",
    "    #candidates = [f\"{model.name}\" for model in aiplatform.Model.list(filter = f\"labels.series={series}\")]\n",
    "    candidates = [f\"{model.display_name}_{model.labels['timestamp']}\" for model in aiplatform.Model.list(filter = f\"labels.series={series}\")  if model.display_name[3:5] == '03'] # if statement filter out the unsupervised models in 03g, 03h, 03i and model in pipeline 2\n",
    "\n",
    "    return result(candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e78b2d5-891c-4e3d-aab6-12381b95159f",
   "metadata": {},
   "source": [
    "#### Component: bqml_evaluate\n",
    "Gather evaluation metrics for a specified BQML model: metrics, confusion matric, ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be4b0fd4-bd61-47da-b4b4-4c01f8200b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from kfp.v2.dsl import Artifact, Input, Metrics, Output, component\n",
    "@component(\n",
    "    base_image = \"python:3.9\",\n",
    "    packages_to_install = ['pandas', 'db-dtypes', 'google-cloud-bigquery', 'google-cloud-storage']\n",
    ")\n",
    "def bqml_evaluate(\n",
    "    project: str,\n",
    "    region: str,\n",
    "    bq_project: str,\n",
    "    bq_dataset: str,\n",
    "    bq_model: str,\n",
    "    bq_test_table: str,\n",
    "    bq_results: str,\n",
    "    best_metric: str,\n",
    "    metrics: Output[Metrics],\n",
    "    class_metrics: Output[ClassificationMetrics]\n",
    ") -> NamedTuple('outputs', [('best_metric', float)]):\n",
    "\n",
    "    # setup\n",
    "    import json\n",
    "    from google.cloud import bigquery\n",
    "    bq = bigquery.Client(project = bq_project)\n",
    "    from google.cloud import storage\n",
    "    gcs = storage.Client(project = project)\n",
    "    from collections import namedtuple\n",
    "    result = namedtuple('outputs', ['best_metric'])\n",
    "    \n",
    "    # BQML: ML.EVALUTE\n",
    "    query = f\"\"\"\n",
    "    SELECT *\n",
    "    FROM ML.EVALUATE (\n",
    "        MODEL `{bq_project}.{bq_dataset}.{bq_model}`,\n",
    "        (SELECT * FROM `{bq_test_table}`)\n",
    "    )\n",
    "    \"\"\"\n",
    "    bq_eval = bq.query(query = query).to_dataframe()\n",
    "    bq_eval = bq_eval.to_dict(orient = 'records')[0]\n",
    "    for key in bq_eval:\n",
    "        metrics.log_metric(key, bq_eval[key])\n",
    "\n",
    "    # BQML: ML.CONFUSION_MATRIX\n",
    "    query = f\"\"\"\n",
    "    SELECT *\n",
    "    FROM ML.CONFUSION_MATRIX (\n",
    "        MODEL `{bq_project}.{bq_dataset}.{bq_model}`,\n",
    "        (SELECT * FROM `{bq_test_table}`)\n",
    "    )\n",
    "    \"\"\"\n",
    "    bq_cm = bq.query(query = query).to_dataframe()\n",
    "    classes = ['Not Fraud', 'Fraud']\n",
    "    # ignore the 'trial_id' column that is included when hyperparameter tuning is used and skip the first=label column\n",
    "    matrix = bq_cm.loc[:, bq_cm.columns != 'trial_id'].iloc[:, 1:].values.tolist()\n",
    "    class_metrics.log_confusion_matrix(classes, matrix)\n",
    "\n",
    "    # BQML: ML.ROC_CURVE\n",
    "    query = f\"\"\"\n",
    "    SELECT *\n",
    "    FROM ML.ROC_CURVE (\n",
    "        MODEL `{bq_project}.{bq_dataset}.{bq_model}`,\n",
    "        (SELECT * FROM `{bq_test_table}`)\n",
    "    )\n",
    "    \"\"\"\n",
    "    bq_roc = bq.query(query = query).to_dataframe()\n",
    "    class_metrics.log_roc_curve(\n",
    "        bq_roc['false_positive_rate'].tolist(),\n",
    "        bq_roc['recall'].tolist(),\n",
    "        bq_roc['threshold'].tolist()\n",
    "    )\n",
    "    \n",
    "    # save bq_eval results to common file {'candidate': bq_eval}\n",
    "    file = f\"bq_eval_{bq_model}.json\"\n",
    "    bq_eval['candidate'] = bq_model\n",
    "    with open(file, 'w') as fp:\n",
    "        json.dump(bq_eval, fp)\n",
    "    \n",
    "    bucket = gcs.bucket(project)\n",
    "    path = bq_results.split(f'gs://{project}/')[-1]\n",
    "    blob = bucket.blob(f\"{path}/{file}\")\n",
    "    blob.upload_from_filename(f\"{file}\")\n",
    "    \n",
    "    return result(bq_eval[best_metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccd098e-8045-4c9c-8577-e7855cbce6e4",
   "metadata": {},
   "source": [
    "#### Component: best_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "328c74bc-d29e-45d9-9512-e6e988860990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from kfp.v2.dsl import Artifact, Input, Metrics, Output, component\n",
    "@component(\n",
    "    base_image = \"python:3.9\",\n",
    "    packages_to_install = ['pandas', 'google-cloud-storage', 'pretty_html_table']\n",
    ")\n",
    "def best_candidate(\n",
    "    project: str,\n",
    "    region: str,\n",
    "    bq_results: str,\n",
    "    best_metric: str,\n",
    "    candidates: list,\n",
    "    metrics: Output[HTML]\n",
    ") -> NamedTuple('outputs', [('best_candidate', str), ('best_metric', float)]):\n",
    "\n",
    "    # setup\n",
    "    import json\n",
    "    import pandas as pd\n",
    "    from pretty_html_table import build_table\n",
    "    from google.cloud import storage\n",
    "    gcs = storage.Client(project = project)\n",
    "    from collections import namedtuple\n",
    "    result = namedtuple('outputs', ['best_candidate', 'best_metric'])\n",
    "    \n",
    "    # retrieve bq_results to a list of dictionaires: bq_evals = [{}, {}, ...]\n",
    "    path = bq_results.split(f'gs://{project}/')[-1]\n",
    "    bucket = gcs.bucket(project)\n",
    "    blobs = list(bucket.list_blobs(prefix = path))\n",
    "    \n",
    "    candidate_evals = []\n",
    "    for blob in blobs:\n",
    "        file = blob.name.split('/')[-1]\n",
    "        blob.download_to_filename(file)\n",
    "        with open(file, 'r') as fp:\n",
    "            evals = json.load(fp)\n",
    "        if evals['candidate'] in candidates:\n",
    "            candidate_evals.append(evals)\n",
    "            \n",
    "    # convert list of dictionaries to pandas dataframe:\n",
    "    candidate_evals = pd.DataFrame(candidate_evals)\n",
    "    \n",
    "    # pick best candidate based on best_metric:\n",
    "    if best_metric in ['accuracy', 'precision', 'recall', 'f1_score', 'roc_auc']:\n",
    "        candidate_evals['best'] = candidate_evals[best_metric].rank(method = 'dense', ascending = False)\n",
    "    elif best_metric in ['log_loss']:\n",
    "        candidate_evals['best'] = candidate_evals[best_metric].rank(method = 'dense', ascending = True)\n",
    "    best_candidate = candidate_evals.loc[candidate_evals['best'] == 1].iloc[0]\n",
    "    \n",
    "    # output evals to HTML Table in metrics:\n",
    "    with open(metrics.path, 'w') as fp:\n",
    "        fp.write(build_table(candidate_evals, 'blue_light'))\n",
    "        \n",
    "    return result(best_candidate['candidate'], best_candidate[best_metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7978a6bb-ee9a-498e-9ec9-41716204b636",
   "metadata": {},
   "source": [
    "#### Component: get_endpoint\n",
    "\n",
    "Look for Vertex AI Endpoint for the series and if missing, create it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e86fac55-f382-4de4-aebd-76ad06ae64e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from kfp.v2.dsl import Artifact, Input, Metrics, Output, component\n",
    "@component(\n",
    "    base_image = \"python:3.9\",\n",
    "    packages_to_install = ['google-cloud-aiplatform']\n",
    ")\n",
    "def get_endpoint(\n",
    "    project: str,\n",
    "    region: str,\n",
    "    series: str,\n",
    "    bq_dataset: str \n",
    ") -> NamedTuple('outputs', [('endpoint_resource_name', str)]):\n",
    "\n",
    "    # setup\n",
    "    from collections import namedtuple\n",
    "    result = namedtuple('outputs', ['endpoint_resource_name'])\n",
    "    \n",
    "    from google.cloud import aiplatform\n",
    "    aiplatform.init(project = project, location = region)\n",
    "    \n",
    "    # retrieve endpoint\n",
    "    endpoints = aiplatform.Endpoint.list(filter = f\"labels.series={series}\")\n",
    "    if endpoints:\n",
    "        endpoint = endpoints[0]\n",
    "        print(f\"Endpoint Exists: {endpoints[0].resource_name}\")\n",
    "    else:\n",
    "        endpoint = aiplatform.Endpoint.create(\n",
    "            display_name = f\"{series}\",\n",
    "            labels = {'series' : f\"{series}\"}    \n",
    "        )\n",
    "        print(f\"Endpoint Created: {endpoint.resource_name}\")\n",
    "    \n",
    "    return result(endpoint.resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf104d1-ff70-4bfb-9a09-a0593a8f24a6",
   "metadata": {},
   "source": [
    "#### Component: get_deployed_model\n",
    "\n",
    "Get the models deployed on the endpoint and return one with most/all traffic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "858db5de-cb97-4b97-82e9-3284d4219a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from kfp.v2.dsl import Artifact, Input, Metrics, Output, component\n",
    "@component(\n",
    "    base_image = \"python:3.9\",\n",
    "    packages_to_install = ['google-cloud-aiplatform']\n",
    ")\n",
    "def get_deployed_model(\n",
    "    project: str,\n",
    "    region: str,\n",
    "    series: str,\n",
    "    endpoint_resource_name: str,\n",
    ") -> NamedTuple('outputs', [('model', str)]):\n",
    "\n",
    "    # setup\n",
    "    from collections import namedtuple\n",
    "    result = namedtuple('outputs', ['model'])\n",
    "    \n",
    "    from google.cloud import aiplatform\n",
    "    aiplatform.init(project = project, location = region)\n",
    "    \n",
    "    # retrieve endpoint\n",
    "    endpoint = aiplatform.Endpoint(endpoint_name = endpoint_resource_name)\n",
    "    \n",
    "    # retrieve deployed model with most traffic and get BQML model name\n",
    "    traffic_split = endpoint.traffic_split\n",
    "    if traffic_split:\n",
    "        deployed_model_id = max(traffic_split, key = traffic_split.get)\n",
    "        if deployed_model_id:\n",
    "            for model in endpoint.list_models():\n",
    "                if model.id == deployed_model_id:\n",
    "                    deployed_model = model.model+f'@{model.model_version_id}'\n",
    "            deployed_model = aiplatform.Model(model_name = deployed_model)\n",
    "            bq_model = deployed_model.display_name+f\"_{deployed_model.labels['timestamp']}\"\n",
    "        else: bq_model = 'none'\n",
    "    else: bq_model = 'none'\n",
    "    \n",
    "    return result(bq_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff0b771-1b67-4eca-939e-44e5c6279086",
   "metadata": {},
   "source": [
    "#### Component: deploy_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89eda5c6-51ab-4457-85ec-d41e79fc2b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from kfp.v2.dsl import Artifact, Input, Metrics, Output, component\n",
    "@component(\n",
    "    base_image = \"python:3.9\",\n",
    "    packages_to_install = ['google-cloud-aiplatform']\n",
    ")\n",
    "def deploy_candidate(\n",
    "    project: str,\n",
    "    region: str,\n",
    "    series: str,\n",
    "    endpoint_resource_name: str,\n",
    "    bq_model: str\n",
    ") -> NamedTuple('outputs', [('model_version', str)]):\n",
    "\n",
    "    DEPLOY_COMPUTE = 'n1-standard-4'\n",
    "    \n",
    "    # setup\n",
    "    from collections import namedtuple\n",
    "    result = namedtuple('outputs', ['model_version'])\n",
    "    \n",
    "    from google.cloud import aiplatform\n",
    "    aiplatform.init(project = project, location = region)\n",
    "    \n",
    "    # retrieve endpoint\n",
    "    endpoint = aiplatform.Endpoint(endpoint_name = endpoint_resource_name)\n",
    "    \n",
    "    # retrieve model\n",
    "    model_display_name = ('_').join(bq_model.split('_')[0:-1])\n",
    "    model_timestamp = bq_model.split('_')[-1]\n",
    "    model_experiment = bq_model.split('_')[1]\n",
    "    model = aiplatform.Model.list(filter = f\"labels.series={series} AND labels.experiment={model_experiment}\")[0]\n",
    "    \n",
    "    # get all versions of the model:\n",
    "    client_options = {\"api_endpoint\": f\"{region}-aiplatform.googleapis.com\"}\n",
    "    model_client = aiplatform.gapic.ModelServiceClient(client_options = client_options)\n",
    "    model_versions = list(model_client.list_model_versions(name = model.resource_name))\n",
    "    for version in model_versions:\n",
    "        if version.labels['timestamp'] == model_timestamp:\n",
    "           model = aiplatform.Model(model_name = version.name) \n",
    "    \n",
    "    # deploy the candidate model to the endpoint with 100% traffic\n",
    "    endpoint.deploy(\n",
    "        model = model,\n",
    "        deployed_model_display_name = model.display_name,\n",
    "        traffic_percentage = 100,\n",
    "        machine_type = DEPLOY_COMPUTE,\n",
    "        min_replica_count = 1,\n",
    "        max_replica_count = 1\n",
    "    )\n",
    "    \n",
    "    # remove models without traffic\n",
    "    for deployed_model in endpoint.list_models():\n",
    "        if deployed_model.id in endpoint.traffic_split:\n",
    "            print(f\"Model {deployed_model.display_name} with version {deployed_model.model_version_id} has traffic = {endpoint.traffic_split[deployed_model.id]}\")\n",
    "        else:\n",
    "            endpoint.undeploy(deployed_model_id = deployed_model.id)\n",
    "            print(f\"Undeploying {deployed_model.display_name} with version {deployed_model.model_version_id} because it has no traffic.\")\n",
    "\n",
    "    return result(model.versioned_resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41be29e5-cf54-4ec4-b230-05ea70bb3759",
   "metadata": {},
   "source": [
    "### 3 - Define Pipeline\n",
    "\n",
    "Recall the Outline, notice it is include as comments in the pipeline definition below:\n",
    "- Candidate selection path:\n",
    "    - Get list of candidate models: Vertex AI Model Registry where labels.series={SERIES} and version_alias=default\n",
    "    - Loop (async) over list of candidate models\n",
    "        - Gather Evaluation: log metrics: evaluation, confusion matrix, ROC curve\n",
    "    - Pick the best candidate model\n",
    "- Current model review path:\n",
    "    - Check for endpoint, create if needed\n",
    "    - Get the deployed model with most traffic \n",
    "    - Condition: if there is a deployed model\n",
    "        - Gather Evaluation: log metrics: evaluation, confusion matrix, ROC curve\n",
    "    - Condition: if there is not a deployed model\n",
    "        - deploy best on endpoint\n",
    "- Compare And update Path:\n",
    "    - Condition: if best > deployed\n",
    "        - deploy best on endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94adf436-290e-4b63-b21d-5738df88fe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from kfp import dsl\n",
    "@dsl.pipeline(\n",
    "    name = f'series-{SERIES}-endpoint-update',\n",
    "    description = 'Update endpoint with best model.'\n",
    ")\n",
    "def endpoint_update_pipeline(\n",
    "    project: str,\n",
    "    region: str,\n",
    "    series: str,\n",
    "    experiment: str,\n",
    "    bq_project: str,\n",
    "    bq_dataset: str,\n",
    "    bq_test_table: str,\n",
    "    bq_results: str,\n",
    "    best_metric: str\n",
    "):\n",
    "    from google_cloud_pipeline_components.types import artifact_types\n",
    "    from kfp.v2.components import importer_node\n",
    "    \n",
    "# - Candidate selection path:\n",
    "    \n",
    "    # - Get list of candidate models: Vertex AI Model Registry where labels.series={SERIES} and version_alias=default\n",
    "    candidate_models = list_series_models(\n",
    "        project = project,\n",
    "        region = region,\n",
    "        series = series\n",
    "    ).set_display_name('List Models in Series').set_caching_options(True)\n",
    "    \n",
    "    # - Loop (async) over list of candidate models\n",
    "    with dsl.ParallelFor(candidate_models.outputs['candidates']) as candidate:\n",
    "        \n",
    "        # - Gather Evaluation: log metrics: evaluation, confusion matrix, ROC curve\n",
    "        candidate_metrics = bqml_evaluate(\n",
    "            project = project,\n",
    "            region = region,\n",
    "            bq_project = bq_project,\n",
    "            bq_dataset = bq_dataset,\n",
    "            bq_model = candidate,\n",
    "            bq_test_table = bq_test_table,\n",
    "            bq_results = bq_results,\n",
    "            best_metric = best_metric\n",
    "        ).set_display_name('Gather Candidate Metrics').set_caching_options(True)\n",
    "    \n",
    "    # - Pick the best candidate model    \n",
    "    best = best_candidate(\n",
    "        project = project,\n",
    "        region = region,\n",
    "        bq_results = bq_results,\n",
    "        best_metric = best_metric,\n",
    "        candidates = candidate_models.outputs['candidates']\n",
    "    ).after(candidate_metrics).set_display_name('Pick The Best Candidate').set_caching_options(True)\n",
    "\n",
    "# - Current model review path:\n",
    "\n",
    "    # - Check for endpoint, create if needed\n",
    "    endpoint = get_endpoint(\n",
    "        project = project,\n",
    "        region = region,\n",
    "        series = series,\n",
    "        bq_dataset = bq_dataset \n",
    "    ).set_display_name('Get the Endpoint').set_caching_options(True)\n",
    "    \n",
    "    # - Get the deployed model with most traffic, if any\n",
    "    current_model = get_deployed_model(\n",
    "        project = project,\n",
    "        region = region,\n",
    "        series = series,\n",
    "        endpoint_resource_name = endpoint.outputs['endpoint_resource_name'] \n",
    "    ).set_display_name('Get The Deployed Model').set_caching_options(True)\n",
    "    \n",
    "    # - Condition: if there is a deployed model\n",
    "    with dsl.Condition(\n",
    "        current_model.outputs['model'] != 'none',\n",
    "        name = 'compare_models'\n",
    "    ):\n",
    "    \n",
    "        # - Gather Evaluation: log metrics: evaluation, confusion matrix, ROC curve\n",
    "        current_metrics = bqml_evaluate(\n",
    "            project = project,\n",
    "            region = region,\n",
    "            bq_project = bq_project,\n",
    "            bq_dataset = bq_dataset,\n",
    "            bq_model = current_model.outputs['model'],\n",
    "            bq_test_table = bq_test_table,\n",
    "            bq_results = bq_results,\n",
    "            best_metric = best_metric\n",
    "        ).set_display_name('Gather Current Metrics').set_caching_options(True)\n",
    "    \n",
    "# - Compare And update Path:\n",
    "\n",
    "        # - Condition: if best > deployed\n",
    "        with dsl.Condition(\n",
    "            best.outputs['best_metric'] > current_metrics.outputs['best_metric'],\n",
    "            name = 'replace_deployed_model'\n",
    "        ):\n",
    "            \n",
    "            # - deploy best on endpoint\n",
    "            deploy = deploy_candidate(\n",
    "                project = project,\n",
    "                region = region,\n",
    "                series = series,\n",
    "                endpoint_resource_name = endpoint.outputs['endpoint_resource_name'],\n",
    "                bq_model = best.outputs['best_candidate']\n",
    "            ).set_display_name('Deploy The Candidate Model').set_caching_options(True)\n",
    "            \n",
    "    # - Condition: if there is not a deployed model\n",
    "    with dsl.Condition(\n",
    "        current_model.outputs['model'] == 'none',\n",
    "        name = 'deploy_model'\n",
    "    ):\n",
    "        \n",
    "        # - deploy best on endpoint\n",
    "        deploy = deploy_candidate(\n",
    "            project = project,\n",
    "            region = region,\n",
    "            series = series,\n",
    "            endpoint_resource_name = endpoint.outputs['endpoint_resource_name'],\n",
    "            bq_model = best.outputs['best_candidate']\n",
    "        ).set_display_name('Deploy The Candidate Model').set_caching_options(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76e41d1-b009-4fbe-b940-0466534f89f5",
   "metadata": {},
   "source": [
    "### 4 - Compile And Run Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6048df17-29fb-4174-916b-9892aae3ddf3",
   "metadata": {},
   "source": [
    "#### Collect Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4763b950-5e86-4f81-b5c4-3a74fc897d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x7fed8e3c9f90>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bq_test_table = f\"{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}_TEST\"\n",
    "query = f\"\"\"\n",
    "CREATE OR REPLACE VIEW `{bq_test_table}` AS\n",
    "    SELECT * EXCEPT({','.join(VAR_OMIT.split())}, splits),\n",
    "    FROM `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}`\n",
    "    WHERE splits = 'TEST'\n",
    "\"\"\"\n",
    "job = bq.query(query = query)\n",
    "job.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61ac603f-c25b-45fd-b1db-2ca64eb2b956",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_values = {\n",
    "    \"project\" : PROJECT_ID,\n",
    "    \"region\" : REGION,\n",
    "    \"experiment\" : EXPERIMENT,\n",
    "    \"series\": SERIES,\n",
    "    \"bq_project\": BQ_PROJECT,\n",
    "    \"bq_dataset\": BQ_DATASET,\n",
    "    \"bq_test_table\": bq_test_table,\n",
    "    \"bq_results\": f\"{URI}/bq_results\",\n",
    "    \"best_metric\": 'accuracy' # accuracy, precision, recall, f1_score, log_loss, roc_auc\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65a8ddc-c632-4a63-ae37-2cd9b163251c",
   "metadata": {},
   "source": [
    "#### Compile Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dd5f5fcf-08b4-4eeb-9f6c-8703a591691b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from kfp.v2 import compiler\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func = endpoint_update_pipeline,\n",
    "    package_path = f\"{DIR}/{EXPERIMENT}.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3546e428-a295-4dff-b381-baa9c99a899e",
   "metadata": {},
   "source": [
    "#### Define Pipeline Job\n",
    "Using compiled pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3acb880-8412-40b4-972b-068e30f0926a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_job = aiplatform.PipelineJob(\n",
    "    display_name = f\"{EXPERIMENT}_tournament\",\n",
    "    template_path = f\"{DIR}/{EXPERIMENT}.json\",\n",
    "    parameter_values = parameter_values,\n",
    "    pipeline_root = f\"{URI}/pipeline_root\",\n",
    "    enable_caching = False, # overrides all component/task settings\n",
    "    labels = {'experiment': EXPERIMENT, 'series': SERIES}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446bff5d-ffca-4d05-8090-fa97f52e9c92",
   "metadata": {},
   "source": [
    "#### Submit Pipeline Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04b64989-573e-4452-bc9c-dfe68dc8bfed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/series-03-endpoint-update-20221003152920\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/1026793852137/locations/us-central1/pipelineJobs/series-03-endpoint-update-20221003152920')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/series-03-endpoint-update-20221003152920?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "response = pipeline_job.submit(\n",
    "    service_account = SERVICE_ACCOUNT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc30d68-1c3b-493a-92c6-b35664d44c37",
   "metadata": {},
   "source": [
    "Using the following link to view the job in the GCP console:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b17567cb-1038-46ca-8f52-e90cf2291f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dashboard can be viewed here:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/series-03-endpoint-update-20221003152920?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "print(f'The Dashboard can be viewed here:\\n{pipeline_job._dashboard_uri()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbd289e-dde8-4c6f-ad9d-c6946793158a",
   "metadata": {},
   "source": [
    "#### Wait On Pipeline Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd7251a9-d2b6-4fa3-a442-b9f644b8675e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/series-03-endpoint-update-20221003152920 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/series-03-endpoint-update-20221003152920 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/series-03-endpoint-update-20221003152920 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/series-03-endpoint-update-20221003152920 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/series-03-endpoint-update-20221003152920 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/series-03-endpoint-update-20221003152920 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/series-03-endpoint-update-20221003152920 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/series-03-endpoint-update-20221003152920\n"
     ]
    }
   ],
   "source": [
    "pipeline_job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbeb5a56-e610-492b-9219-90ae61194059",
   "metadata": {},
   "source": [
    "---\n",
    "## Dashboard Screenshot:\n",
    "\n",
    "<img src=\"../architectures/notebooks/03/pipeline_ex1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01108ed-4c60-44a3-b4d2-e8d24e5d0012",
   "metadata": {},
   "source": [
    "---\n",
    "## Work In Progress\n",
    "\n",
    "Use Vertex AI ML Metadata Artifact Types:\n",
    " - [Reference](https://cloud.google.com/vertex-ai/docs/pipelines/artifact-types)\n",
    " - [Consume or produce artifact in your component](https://cloud.google.com/vertex-ai/docs/pipelines/use-components#consume_or_produce_artifacts_in_your_component)\n",
    "\n",
    "```\n",
    "    # import prebuilt components\n",
    "    from google_cloud_pipeline_components.v1.bigquery import (\n",
    "        BigqueryEvaluateModelJobOp,\n",
    "        BigqueryMLConfusionMatrixJobOp,\n",
    "        BigqueryMLRocCurveJobOp\n",
    "    )\n",
    "    from google_cloud_pipeline_components.types import artifact_types\n",
    "    from kfp.v2.components import importer_node\n",
    "\n",
    "...\n",
    "\n",
    "    with dsl.ParallelFor(candidate_models.outputs['candidates']) as candidate:\n",
    "        #candidate.set_display_name(str(candidate_models.outputs['candidates']))\n",
    "        \n",
    "        bqml_model = importer_node.importer(\n",
    "            artifact_uri = artifact_uri,\n",
    "            artifact_class = artifact_types.BQMLModel,\n",
    "            metadata = {\n",
    "                'projectId': \"statmike-mlops-349915\",\n",
    "                'datasetId': \"fraud\",\n",
    "                'modelId': \"03f_fraud_20220909135610\"\n",
    "            }\n",
    "        )\n",
    "        bq_eval = BigqueryEvaluateModelJobOp(\n",
    "            project = project,\n",
    "            location = region,\n",
    "            model = bqml_model.outputs['artifact'],\n",
    "            table_name = bq_test_table\n",
    "        )\n",
    "        bq_cm = BigqueryMLConfusionMatrixJobOp(\n",
    "            project = project,\n",
    "            location = region,\n",
    "            model = bqml_model.outputs['artifact'],\n",
    "            table_name = bq_test_table\n",
    "        )\n",
    "        bq_roc = BigqueryMLRocCurveJobOp(\n",
    "            project = project,\n",
    "            location = region,\n",
    "            model = bqml_model.outputs['artifact'],\n",
    "            table_name = bq_test_table\n",
    "        ) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24191d22-46dd-4145-bbb9-ec4a6784a40a",
   "metadata": {},
   "source": [
    "---\n",
    "## Remove Resources\n",
    "see notebook \"99 - Cleanup\""
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-3.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m94"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
