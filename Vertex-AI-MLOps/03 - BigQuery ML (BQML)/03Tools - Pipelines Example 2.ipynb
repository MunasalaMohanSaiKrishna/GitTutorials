{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b59f1fb-5557-4f89-9ee6-505e1ccc8509",
   "metadata": {},
   "source": [
    "# 03Tools - Pipelines Example 2\n",
    "\n",
    "**Conditionally update endpoint**\n",
    "\n",
    ">**Note:** Formerly named `03c - BQML + Vertex AI > Pipelines - automated pipelines for updating models`.  This [link](https://github.com/statmike/vertex-ai-mlops/blob/fd442b458c710a0a7afdc41bae690d2a3282e93c/03c%20-%20BQML%20%2B%20Vertex%20AI%20%3E%20Pipelines%20-%20automated%20pipelines%20for%20updating%20models.ipynb) goes to the previous version featured in the video.  The version below has been fully update to match the parameterization of revised notebooks in this `03` series while preserving the orignal operational example - create a challenger model that is used to conditionally update an endpoint.\n",
    "\n",
    "As time goes on change occurs:\n",
    "- inputs to our models may shift in distribution compared to when the model was trained - called training-serving skew\n",
    "- inputs to out models may shift over time - called prediction drift\n",
    "- new inputs/features may become available\n",
    "- a better model may be created\n",
    "\n",
    "In the `03Tools - Predictions` notebook we deployed the model built with BQML in the `03a` notebook to a Vertex AI Endpoint for online prediction.  In this notebook we will build a challenger model with the same training data, also using BQML but with a different model type - a deep neural network similar what we build in the `05` series of notebooks.  We will construct a Vertex AI Pipeline to orchestrate the process of building the new model, comparing to the deployed mode, and conditionally replacing the deployed model with the new one.  \n",
    "\n",
    "This process could be triggered based on time elapsed, amount of new data, detected training-serving skew or even prediction drift by using Vertex AI Monitoring.  \n",
    "\n",
    "**Video Walkthrough of this notebook:**\n",
    "\n",
    "Includes conversational walkthrough and more explanatory information than the notebook:\n",
    "\n",
    "<p align=\"center\" width=\"100%\"><center><a href=\"https://youtu.be/kzDd94KucBQ\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"../architectures/thumbnails/playbutton/03tools_pipe2.png\" width=\"40%\"></a></center></p>\n",
    "\n",
    "**Prerequisites:**\n",
    "-  [03a - BQML Logistic Regression](03a%20-%20BQML%20Logistic%20Regression.ipynb)\n",
    "-  [03Tools - Predictions](03Tools%20-%20Predictions.ipynb)\n",
    "\n",
    "**Resources:**\n",
    "- Pipelines:\n",
    "    - [Vertex AI Pipelines](https://cloud.google.com/vertex-ai/docs/pipelines/introduction)\n",
    "        - [Kubeflow](https://www.kubeflow.org/docs/components/pipelines/v2/author-a-pipeline/)\n",
    "            - [Install the Kubeflow Pipelines SDK](https://www.kubeflow.org/docs/components/pipelines/v1/sdk/install-sdk/)\n",
    "        - [Google Cloud Pre-Built Pipeline Components](https://cloud.google.com/vertex-ai/docs/pipelines/gcpc-list)\n",
    "            - [SDK Reference](https://google-cloud-pipeline-components.readthedocs.io)\n",
    "- [BigQuery](https://cloud.google.com/bigquery)\n",
    "    - [Documentation:](https://cloud.google.com/bigquery/docs/query-overview)\n",
    "    - [API:](https://cloud.google.com/bigquery/docs/reference/libraries-overview)\n",
    "        - [Clients](https://cloud.google.com/bigquery/docs/reference/libraries)\n",
    "            - [Python SDK:](https://github.com/googleapis/python-bigquery)\n",
    "            - [Python Library Reference:](https://cloud.google.com/python/docs/reference/bigquery/latest)\n",
    "- [Vertex AI](https://cloud.google.com/vertex-ai)\n",
    "    - [Documentation:](https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform)\n",
    "    - [API:](https://cloud.google.com/vertex-ai/docs/reference)\n",
    "        - [Clients:](https://cloud.google.com/vertex-ai/docs/start/client-libraries)\n",
    "            - [Python SDK:](https://github.com/googleapis/python-aiplatform)\n",
    "            - [Python Library Reference:](https://cloud.google.com/python/docs/reference/aiplatform/latest)\n",
    "\n",
    "**Conceptual Flow & Workflow**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img alt=\"Conceptual Flow\" src=\"../architectures/slides/03tools_pipe2_arch.png\" width=\"45%\">\n",
    "&nbsp; &nbsp; &nbsp; &nbsp;\n",
    "  <img alt=\"Workflow\" src=\"../architectures/slides/03tools_pipe2_console.png\" width=\"45%\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39de3982-2555-4d5c-bae6-8e7d35710557",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f870ab11-b5dc-4378-830c-b39feaaa5384",
   "metadata": {},
   "source": [
    "inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de005cc5-f141-4593-9f00-6d4da186424f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'statmike-mlops-349915'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb73f2d6-e658-445c-8a2a-3c65edfe423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "EXPERIMENT = 'pipeline_ex2'\n",
    "SERIES = '03'\n",
    "\n",
    "# source data\n",
    "BQ_PROJECT = PROJECT_ID\n",
    "BQ_DATASET = 'fraud'\n",
    "BQ_TABLE = 'fraud_prepped'\n",
    "\n",
    "# Model Training\n",
    "VAR_TARGET = 'Class'\n",
    "VAR_OMIT = 'transaction_id' # add more variables to the string with space delimiters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc1e984-dcde-4348-a72a-6848ac2a7538",
   "metadata": {},
   "source": [
    "packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "968c1a4a-512f-4553-8e8c-130df1100a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from google.cloud import bigquery\n",
    "\n",
    "from datetime import datetime\n",
    "from typing import NamedTuple\n",
    "\n",
    "import kfp # used for dsl.pipeline\n",
    "import kfp.v2.dsl as dsl # used for dsl.component, dsl.Output, dsl.Input, dsl.Artifact, dsl.Model, ...\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216f8e48-531b-45b3-ad29-b64557cab774",
   "metadata": {},
   "source": [
    "clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cbd2df68-d747-45e7-9448-ec9454508407",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "bq = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f01eff3-dd34-4842-b477-bd9d72314a8c",
   "metadata": {},
   "source": [
    "parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4ca5abe-d716-4376-b7e7-9a8b6f8d45e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "BUCKET = PROJECT_ID\n",
    "URI = f\"gs://{BUCKET}/{SERIES}/{EXPERIMENT}/pipelines\"\n",
    "RUN_NAME = f'run-{TIMESTAMP}'\n",
    "DIR = f\"temp/{EXPERIMENT}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83e9f546-515b-4112-bd54-b9ab435026c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1026793852137-compute@developer.gserviceaccount.com'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SERVICE_ACCOUNT = !gcloud config list --format='value(core.account)' \n",
    "SERVICE_ACCOUNT = SERVICE_ACCOUNT[0]\n",
    "SERVICE_ACCOUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d5e930-45bc-4219-b299-1acd134b8fd5",
   "metadata": {},
   "source": [
    "List the service accounts current roles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5843992-d441-4868-b3cc-09a93a8bc844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROLE\n",
      "roles/bigquery.admin\n",
      "roles/owner\n",
      "roles/run.admin\n",
      "roles/storage.objectAdmin\n"
     ]
    }
   ],
   "source": [
    "!gcloud projects get-iam-policy $PROJECT_ID --filter=\"bindings.members:$SERVICE_ACCOUNT\" --format='table(bindings.role)' --flatten=\"bindings[].members\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eba5f76-2053-4700-99db-98264bb14fc0",
   "metadata": {},
   "source": [
    ">Note: If the resulting list is missing [roles/storage.objectAdmin](https://cloud.google.com/storage/docs/access-control/iam-roles) then [revisit the setup notebook](../00%20-%20Setup/00%20-%20Environment%20Setup.ipynb#permissions) and add this permission to the service account with the provided instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f1d92b-35ec-4925-8aa2-e63a0dd84267",
   "metadata": {},
   "source": [
    "environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91e41643-6611-41dc-9519-ac0b129457d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {DIR}\n",
    "!mkdir -p {DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b752b9d4-1c24-4bea-ab77-4cd88d7356b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## Custom Components (KFP)\n",
    "\n",
    "Vertex AI Pipelines are made up of components that run independently with inputs and outputs that connect to form a graph - the pipeline.  For this notebook workflow the following custom components are used to orchestrate the training of a challenger model, evaluating the challenger and an existing model, comparing them based on model metrics, if the challenger is better then replace the model already deployed on an existing endpoint.  These custom components are constructed as python functions!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabaefb8-f1c9-41cd-8b6f-32a1e2be8715",
   "metadata": {},
   "source": [
    "### Get The Deployed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7eccaa5-a990-4a15-88aa-15a313dbfb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image = \"python:3.9\",\n",
    "    packages_to_install = ['google-cloud-aiplatform']\n",
    ")\n",
    "def get_deployed_model(\n",
    "    project: str,\n",
    "    region: str,\n",
    "    series: str,\n",
    "    bqml_model: dsl.Output[dsl.Artifact],\n",
    "    vertex_endpoint: dsl.Output[dsl.Artifact]\n",
    "):\n",
    "\n",
    "    # setup\n",
    "    from google.cloud import aiplatform\n",
    "    aiplatform.init(project = project, location = region)\n",
    "\n",
    "    # retrieve (or create) endpoint\n",
    "    endpoints = aiplatform.Endpoint.list(filter = f\"display_name={series} AND labels.series={series}\")\n",
    "    if endpoints:\n",
    "        endpoint = endpoints[0]\n",
    "        print(f\"Endpoint Exists: {endpoints[0].resource_name}\")\n",
    "    else:\n",
    "        endpoint = aiplatform.Endpoint.create(\n",
    "            display_name = f\"{series}\",\n",
    "            labels = {'series' : f\"{series}\"}    \n",
    "        )\n",
    "        print(f\"Endpoint Created: {endpoint.resource_name}\")\n",
    "    \n",
    "    # retrieve deployed model with most traffic and get BQML model name\n",
    "    traffic_split = endpoint.traffic_split\n",
    "    if traffic_split:\n",
    "        deployed_model_id = max(traffic_split, key = traffic_split.get)\n",
    "        if deployed_model_id:\n",
    "            for model in endpoint.list_models():\n",
    "                if model.id == deployed_model_id:\n",
    "                    deployed_model = model.model+f'@{model.model_version_id}'\n",
    "            deployed_model = aiplatform.Model(model_name = deployed_model)\n",
    "            bq_model = deployed_model.display_name+f\"_{deployed_model.labels['timestamp']}\"\n",
    "        else: bq_model = 'none'\n",
    "    else: bq_model = 'none'\n",
    "    \n",
    "    bqml_model.uri = bq_model \n",
    "    vertex_endpoint.uri = endpoint.resource_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ebcab1-0670-4c28-9993-0d8d4bb7a78e",
   "metadata": {},
   "source": [
    "### Model Metrics\n",
    "- Get Predictions for Test data from BigQuery Model\n",
    "- Calculate [average precision for the precision-recall curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a8ff6d61-6e04-4a2a-92f0-cd1fc508acd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image = 'python:3.9',\n",
    "    packages_to_install = ['pandas','db-dtypes','pyarrow','sklearn','google-cloud-bigquery']\n",
    ")\n",
    "def bqml_eval(\n",
    "    project: str,\n",
    "    region: str,\n",
    "    var_target: str,\n",
    "    bq_project: str,\n",
    "    bq_dataset: str,\n",
    "    bq_table: str,\n",
    "    bqml_model: dsl.Input[dsl.Model],\n",
    "    metrics: dsl.Output[dsl.Metrics],\n",
    "    metricsc: dsl.Output[dsl.ClassificationMetrics]\n",
    ") -> NamedTuple(\"model_eval\", [(\"metric\", float)]):\n",
    "\n",
    "    # setup\n",
    "    from collections import namedtuple\n",
    "    from sklearn.metrics import average_precision_score, confusion_matrix\n",
    "    from google.cloud import bigquery\n",
    "    bq = bigquery.Client(project = project)\n",
    "\n",
    "    query = f\"\"\"\n",
    "    SELECT {var_target}, predicted_{var_target}, prob, splits \n",
    "    FROM ML.PREDICT (MODEL `{bq_project}.{bq_dataset}.{bqml_model.uri}`,(\n",
    "        SELECT *\n",
    "        FROM `{bq_project}.{bq_dataset}.{bq_table}`\n",
    "        WHERE splits = 'TEST')\n",
    "      ), UNNEST(predicted_{var_target}_probs)\n",
    "    WHERE label=1\n",
    "    \"\"\"\n",
    "    pred = bq.query(query = query).to_dataframe()\n",
    "\n",
    "    auPRC = average_precision_score(pred[var_target].astype(int), pred['prob'], average='micro')    \n",
    "    metrics.log_metric('auPRC', auPRC)\n",
    "    metricsc.log_confusion_matrix(['Not Fraud', 'Fraud'], confusion_matrix(pred[var_target].astype(int), pred[f'predicted_{var_target}'].astype(int)).tolist())\n",
    "    \n",
    "    model_eval = namedtuple(\"model_eval\", [\"metric\"])\n",
    "    return model_eval(metric = float(auPRC))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d2dc53-92e1-477e-9a17-6418ca36ab0d",
   "metadata": {},
   "source": [
    "### BigQuery - Train DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0bd02b99-213d-454e-a372-eafaf14e56b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image = 'python:3.9',\n",
    "    packages_to_install = ['google-cloud-bigquery']\n",
    ")\n",
    "def bqml_dnn(\n",
    "    project: str,\n",
    "    region: str,\n",
    "    series: str,\n",
    "    experiment: str,\n",
    "    timestamp: str,\n",
    "    var_target: str,\n",
    "    var_omit: str,\n",
    "    bq_project: str,\n",
    "    bq_dataset: str,\n",
    "    bq_table: str,\n",
    "    bqml_model: dsl.Output[dsl.Artifact]\n",
    ") -> NamedTuple(\"bqml_training\", [(\"query\", str)]):\n",
    "    \n",
    "    from collections import namedtuple\n",
    "    from google.cloud import bigquery\n",
    "    bq = bigquery.Client(project = project)\n",
    "    \n",
    "    bq_model = f'{series}_{experiment}_{timestamp}'\n",
    "    query = f\"\"\"\n",
    "    CREATE OR REPLACE MODEL `{bq_project}.{bq_dataset}.{bq_model}`\n",
    "    OPTIONS\n",
    "        (model_type = 'DNN_CLASSIFIER',\n",
    "            auto_class_weights = FALSE,\n",
    "            input_label_cols = ['{var_target}'],\n",
    "            data_split_col = 'custom_splits',\n",
    "            data_split_method = 'CUSTOM',\n",
    "            EARLY_STOP = FALSE,\n",
    "            OPTIMIZER = 'SGD',\n",
    "            HIDDEN_UNITS = [64, 32],\n",
    "            LEARN_RATE = 0.001,\n",
    "            ACTIVATION_FN = 'SIGMOID',\n",
    "            MAX_ITERATIONS = 15,\n",
    "            HPARAM_TUNING_ALGORITHM = 'VIZIER_DEFAULT',\n",
    "            HPARAM_TUNING_OBJECTIVES = ['ROC_AUC'],\n",
    "            DROPOUT = HPARAM_RANGE(0, 0.8),\n",
    "            BATCH_SIZE = HPARAM_RANGE(8, 500),\n",
    "            MAX_PARALLEL_TRIALS = 5,\n",
    "            NUM_TRIALS = 10\n",
    "        ) AS\n",
    "    SELECT * EXCEPT({','.join(var_omit.split())}, splits),\n",
    "        CASE\n",
    "            WHEN splits = 'VALIDATE' THEN 'EVAL'\n",
    "            ELSE splits\n",
    "        END AS custom_splits\n",
    "    FROM `{bq_project}.{bq_dataset}.{bq_table}`\n",
    "    WHERE splits != 'TEST'\n",
    "    \"\"\"\n",
    "    job = bq.query(query = query)\n",
    "    job.result()\n",
    "    bqml_model.uri = bq_model\n",
    "    \n",
    "    result = namedtuple(\"bqml_training\", [\"query\"])\n",
    "                \n",
    "    return result(query = str(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f11d778-fea2-4bfd-a2d3-a896e4e4d1af",
   "metadata": {},
   "source": [
    "### Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e6ce2e3d-30a8-43dd-90b6-89f0c978ebd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component\n",
    "def model_compare(\n",
    "    base_metric: float,\n",
    "    challenger_metric: float,\n",
    ") -> bool: \n",
    "    \n",
    "    if base_metric < challenger_metric:\n",
    "        replace = True\n",
    "    else:\n",
    "        replace = False\n",
    "    \n",
    "    return replace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bf22f1-8e7b-4697-916a-b02c9fb127c9",
   "metadata": {},
   "source": [
    "### Export BQML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b3ac3753-f7ee-437c-bcf6-63deed2a2109",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image = 'python:3.9',\n",
    "    packages_to_install = ['google-cloud-bigquery', 'google-cloud-aiplatform']\n",
    ")\n",
    "def bqml_export(\n",
    "    project: str,\n",
    "    region: str,\n",
    "    series: str,\n",
    "    experiment: str,\n",
    "    timestamp: str,\n",
    "    uri: str,\n",
    "    run_name: str,\n",
    "    bq_project: str,\n",
    "    bq_dataset: str,\n",
    "    bqml_model: dsl.Input[dsl.Model],\n",
    "    tf_model: dsl.Output[dsl.Artifact],\n",
    "    vertex_model: dsl.Output[dsl.Artifact]\n",
    "):\n",
    "    \n",
    "    # hardcoded parameter\n",
    "    deploy_image = 'us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-3:latest'\n",
    "    \n",
    "    # setup\n",
    "    from google.cloud import bigquery\n",
    "    bq = bigquery.Client(project = project)\n",
    "    \n",
    "    from google.cloud import aiplatform\n",
    "    aiplatform.init(project = project, location = region)\n",
    "    \n",
    "    # export BQML Challenger Model\n",
    "    query = f\"\"\"\n",
    "    EXPORT MODEL `{bq_project}.{bq_dataset}.{bqml_model.uri}`\n",
    "        OPTIONS (URI = '{uri}/models/{timestamp}/model')\n",
    "    \"\"\"\n",
    "    export = bq.query(query = query)\n",
    "    export.result()\n",
    "    \n",
    "    # upload model to Vertex AI Model Registry\n",
    "    modelmatch = aiplatform.Model.list(filter = f'display_name={series}_{experiment} AND labels.series={series} AND labels.experiment={experiment}')\n",
    "\n",
    "    upload_model = True\n",
    "    if modelmatch:\n",
    "        print(\"Model Already in Registry:\")\n",
    "        if RUN_NAME in modelmatch[0].version_aliases:\n",
    "            print(\"This version already loaded, no action taken.\")\n",
    "            upload_model = False\n",
    "            model = aiplatform.Model(model_name = modelmatch[0].resource_name)\n",
    "        else:\n",
    "            print('Loading model as new default version.')\n",
    "            parent_model =  modelmatch[0].resource_name\n",
    "    else:\n",
    "        print('This is a new model, adding to model registry as version 1')\n",
    "        parent_model = ''\n",
    "\n",
    "    if upload_model:\n",
    "        model = aiplatform.Model.upload(\n",
    "            display_name = f'{series}_{experiment}',\n",
    "            model_id = f'model_{series}_{experiment}',\n",
    "            parent_model = parent_model,\n",
    "            serving_container_image_uri = deploy_image,\n",
    "            artifact_uri = f\"{uri}/models/{timestamp}/model\",\n",
    "            is_default_version = True,\n",
    "            version_aliases = [run_name],\n",
    "            version_description = run_name,\n",
    "            labels = {'series' : f'{series}', 'experiment' : f'{experiment}', 'timestamp': f'{timestamp}', 'run_name' : f'{run_name}'}\n",
    "        )  \n",
    "    \n",
    "    tf_model.uri = f'{uri}/models/{timestamp}/model'\n",
    "    vertex_model.uri = model.resource_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bdb4a1-a1b7-4403-bc44-bce46b981c91",
   "metadata": {},
   "source": [
    "### Replace Model On Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2433281e-390d-4ab5-bcfa-c171a72f7b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.component(\n",
    "    base_image = 'python:3.9',\n",
    "    packages_to_install = ['google-cloud-aiplatform']\n",
    ")\n",
    "def endpoint_update(\n",
    "    project: str,\n",
    "    region: str,\n",
    "    series: str,\n",
    "    experiment: str,\n",
    "    vertex_endpoint: dsl.Input[dsl.Artifact],\n",
    "    vertex_model: dsl.Input[dsl.Model]\n",
    "):\n",
    "    \n",
    "    # hardcoded parameter\n",
    "    deploy_compute = 'n1-standard-4'\n",
    "    \n",
    "    # setup\n",
    "    from google.cloud import aiplatform\n",
    "    aiplatform.init(project = project, location = region)\n",
    "\n",
    "    # retrieve endpoint\n",
    "    endpoint = aiplatform.Endpoint(vertex_endpoint.uri)\n",
    "    \n",
    "    # retrieve model\n",
    "    model = aiplatform.Model(vertex_model.uri)\n",
    "    \n",
    "    # deploy model to endpoint with 100% traffic\n",
    "    endpoint.deploy(\n",
    "        model = model,\n",
    "        deployed_model_display_name = model.display_name,\n",
    "        traffic_percentage = 100,\n",
    "        machine_type = deploy_compute,\n",
    "        min_replica_count = 1,\n",
    "        max_replica_count = 1\n",
    "    )\n",
    "    \n",
    "    # remove 0 traffic models\n",
    "    for deployed_model in endpoint.list_models():\n",
    "        if deployed_model.id in endpoint.traffic_split:\n",
    "            print(f\"Model {deployed_model.display_name} with version {deployed_model.model_version_id} has traffic = {endpoint.traffic_split[deployed_model.id]}\")\n",
    "        else:\n",
    "            endpoint.undeploy(deployed_model_id = deployed_model.id)\n",
    "            print(f\"Undeploying {deployed_model.display_name} with version {deployed_model.model_version_id} because it has no traffic.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9535c2f-0f05-4c15-89de-c6cf135f7dd3",
   "metadata": {},
   "source": [
    "---\n",
    "## Pipeline (KFP) Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8d0342ef-5792-4060-afbd-01ca1cf9ef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "    name = f'series-{SERIES}-endpoint-challenger',\n",
    "    description = 'Update endpoint with challenger model (conditionally).'\n",
    ")\n",
    "def pipeline(\n",
    "    project: str,\n",
    "    region: str,\n",
    "    series: str,\n",
    "    experiment: str,\n",
    "    timestamp: str,\n",
    "    bq_project: str,\n",
    "    bq_dataset: str,\n",
    "    bq_table: str,\n",
    "    var_target: str,\n",
    "    var_omit: str,\n",
    "    uri: str,\n",
    "    run_name: str\n",
    "):\n",
    "   \n",
    "    # get the current model\n",
    "    current_model = get_deployed_model(\n",
    "        project = project,\n",
    "        region = region,\n",
    "        series = series\n",
    "    ).set_display_name('Get Current Model').set_caching_options(False)\n",
    "\n",
    "    # get AUC for current model\n",
    "    base_model_eval = bqml_eval(\n",
    "        project = project,\n",
    "        region = region,\n",
    "        var_target = var_target,\n",
    "        bq_project = bq_project,\n",
    "        bq_dataset = bq_dataset,\n",
    "        bq_table = bq_table,\n",
    "        bqml_model = current_model.outputs['bqml_model']\n",
    "    ).set_display_name('Metric for Current Model').set_caching_options(False)\n",
    "    \n",
    "    # train challenger model with BQML\n",
    "    challenger_model = bqml_dnn(\n",
    "        project = project,\n",
    "        region = region,\n",
    "        series = series,\n",
    "        experiment = experiment,\n",
    "        timestamp = timestamp,\n",
    "        var_target = var_target,\n",
    "        var_omit = var_omit,\n",
    "        bq_project = bq_project,\n",
    "        bq_dataset = bq_dataset,\n",
    "        bq_table = bq_table\n",
    "    ).set_display_name('Train Challenger Model').set_caching_options(True)\n",
    "    \n",
    "    # get AUC for challenger model\n",
    "    challenger_model_eval = bqml_eval(\n",
    "        project = project,\n",
    "        region = region,\n",
    "        var_target = var_target,\n",
    "        bq_project = bq_project,\n",
    "        bq_dataset = bq_dataset,\n",
    "        bq_table = bq_table,\n",
    "        bqml_model = challenger_model.outputs['bqml_model']\n",
    "    ).set_display_name('Metric for Challenger Model').set_caching_options(False)\n",
    "    challenger_model_eval.after(challenger_model)\n",
    "    \n",
    "    # compare models\n",
    "    compare = model_compare(\n",
    "        base_metric = base_model_eval.outputs[\"metric\"],\n",
    "        challenger_metric = challenger_model_eval.outputs[\"metric\"]\n",
    "    ).set_display_name('Compare Models')\n",
    "    \n",
    "    # conditional deployment\n",
    "    with dsl.Condition(\n",
    "        compare.output == 'true',\n",
    "        name = \"replace_model\"\n",
    "    ):\n",
    "        # export BQML model to Vertex AI Model Registry\n",
    "        export = bqml_export(\n",
    "            project = project,\n",
    "            region = region,\n",
    "            series = series,\n",
    "            experiment = experiment,\n",
    "            timestamp = timestamp,\n",
    "            uri = uri,\n",
    "            run_name = run_name,\n",
    "            bq_project = bq_project,\n",
    "            bq_dataset = bq_dataset,\n",
    "            bqml_model = challenger_model.outputs[\"bqml_model\"]\n",
    "        ).set_display_name('Export BQML Model')\n",
    "        \n",
    "        # replace model on endpoint (03b)\n",
    "        replace = endpoint_update(\n",
    "            project = project,\n",
    "            region = region,\n",
    "            series = series,\n",
    "            experiment = experiment,\n",
    "            vertex_endpoint = current_model.outputs['vertex_endpoint'],\n",
    "            vertex_model = export.outputs['vertex_model']\n",
    "        ).set_display_name('Deploy The Challenger Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bfa7eb-910f-47b8-b1d2-a2ab0ce552ce",
   "metadata": {},
   "source": [
    "---\n",
    "## Compile And Run Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf95030-c36c-460f-9cfe-ede7aa7b5621",
   "metadata": {},
   "source": [
    "### Compile Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ed32c99d-841a-49c2-a9db-a413b41c08ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_values = {\n",
    "    \"project\" : PROJECT_ID,\n",
    "    \"region\" : REGION,\n",
    "    \"series\": SERIES,\n",
    "    \"experiment\" : EXPERIMENT,\n",
    "    \"timestamp\": TIMESTAMP,\n",
    "    \"bq_project\": BQ_PROJECT,\n",
    "    \"bq_dataset\": BQ_DATASET,\n",
    "    \"bq_table\": BQ_TABLE,\n",
    "    \"var_target\": VAR_TARGET,\n",
    "    \"var_omit\": VAR_OMIT,\n",
    "    \"uri\": URI,\n",
    "    \"run_name\": RUN_NAME\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a936b132-adb8-4dcd-b8a1-ec68c1743a3a",
   "metadata": {},
   "source": [
    "### Compile Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "47369f8c-8a42-4e7d-8920-3d9e038a10bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/kfp/v2/compiler/compiler.py:1295: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
      "  category=FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "# from kfp.v2 import compiler\n",
    "kfp.v2.compiler.Compiler().compile(\n",
    "    pipeline_func = pipeline,\n",
    "    package_path = f\"{DIR}/{EXPERIMENT}.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8d0797-3f30-41b4-82af-a82c33f26133",
   "metadata": {},
   "source": [
    "### Define Pipeline Job\n",
    "\n",
    "Using compiled pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e38dd6b9-9297-402d-9856-cf3731ccaeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_job = aiplatform.PipelineJob(\n",
    "    display_name = f'{EXPERIMENT}',\n",
    "    template_path = f\"{DIR}/{EXPERIMENT}.json\",\n",
    "    pipeline_root = f\"{URI}/pipeline_root\",\n",
    "    parameter_values = parameter_values,\n",
    "    enable_caching = False, # overrides all component/task settings\n",
    "    labels = {'series': SERIES, 'experiment': EXPERIMENT}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1429e4d-9293-48f8-997a-eb85d562b56c",
   "metadata": {},
   "source": [
    "### Submit Pipeline Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "51c4118c-616f-4285-bb1d-928f954ad9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/series-03-endpoint-challenger-20221004192647\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/1026793852137/locations/us-central1/pipelineJobs/series-03-endpoint-challenger-20221004192647')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/series-03-endpoint-challenger-20221004192647?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "response = pipeline_job.submit(\n",
    "    service_account = SERVICE_ACCOUNT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2320f1-bcd4-4c23-a739-e9c932625cdd",
   "metadata": {},
   "source": [
    "Using the following link to view the job in the GCP console:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b17567cb-1038-46ca-8f52-e90cf2291f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dashboard can be viewed here:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/series-03-endpoint-challenger-20221004192647?project=1026793852137\n"
     ]
    }
   ],
   "source": [
    "print(f'The Dashboard can be viewed here:\\n{pipeline_job._dashboard_uri()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a537079d-839a-4cba-bdf7-b6df8b81627d",
   "metadata": {},
   "source": [
    "#### Wait On Pipeline Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dd7251a9-d2b6-4fa3-a442-b9f644b8675e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/series-03-endpoint-challenger-20221004192647 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/series-03-endpoint-challenger-20221004192647 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/series-03-endpoint-challenger-20221004192647 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/series-03-endpoint-challenger-20221004192647 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/series-03-endpoint-challenger-20221004192647 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/series-03-endpoint-challenger-20221004192647 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/series-03-endpoint-challenger-20221004192647 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/series-03-endpoint-challenger-20221004192647 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/series-03-endpoint-challenger-20221004192647 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/series-03-endpoint-challenger-20221004192647 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/series-03-endpoint-challenger-20221004192647 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/series-03-endpoint-challenger-20221004192647 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/series-03-endpoint-challenger-20221004192647 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/series-03-endpoint-challenger-20221004192647 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/series-03-endpoint-challenger-20221004192647 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/series-03-endpoint-challenger-20221004192647 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/series-03-endpoint-challenger-20221004192647 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/series-03-endpoint-challenger-20221004192647 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/series-03-endpoint-challenger-20221004192647 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob projects/1026793852137/locations/us-central1/pipelineJobs/series-03-endpoint-challenger-20221004192647 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "PipelineJob run completed. Resource name: projects/1026793852137/locations/us-central1/pipelineJobs/series-03-endpoint-challenger-20221004192647\n"
     ]
    }
   ],
   "source": [
    "pipeline_job.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3099c0cf-2304-46cb-b993-2311f75ad241",
   "metadata": {},
   "source": [
    "### Retrieve Pipeline Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "002c0d7f-8bdd-4380-828b-cae9dc4c0b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipeline_name</th>\n",
       "      <th>run_name</th>\n",
       "      <th>param.input:var_target</th>\n",
       "      <th>param.input:timestamp</th>\n",
       "      <th>param.input:bq_table</th>\n",
       "      <th>param.input:uri</th>\n",
       "      <th>param.input:bq_dataset</th>\n",
       "      <th>param.input:experiment</th>\n",
       "      <th>param.input:run_name</th>\n",
       "      <th>param.input:series</th>\n",
       "      <th>param.input:project</th>\n",
       "      <th>param.input:region</th>\n",
       "      <th>param.input:var_omit</th>\n",
       "      <th>param.input:bq_project</th>\n",
       "      <th>metric.confusionMatrix</th>\n",
       "      <th>metric.auPRC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>series-03-endpoint-challenger</td>\n",
       "      <td>series-03-endpoint-challenger-20221004192647</td>\n",
       "      <td>Class</td>\n",
       "      <td>20221004192552</td>\n",
       "      <td>fraud_prepped</td>\n",
       "      <td>gs://statmike-mlops-349915/03/pipeline_ex2/pip...</td>\n",
       "      <td>fraud</td>\n",
       "      <td>pipeline_ex2</td>\n",
       "      <td>run-20221004192552</td>\n",
       "      <td>03</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>us-central1</td>\n",
       "      <td>transaction_id</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>{'rows': [{'row': [27969.0, 486.0]}, {'row': [...</td>\n",
       "      <td>0.764713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>series-03-endpoint-challenger</td>\n",
       "      <td>series-03-endpoint-challenger-20221004152232</td>\n",
       "      <td>Class</td>\n",
       "      <td>20221004152128</td>\n",
       "      <td>fraud_prepped</td>\n",
       "      <td>gs://statmike-mlops-349915/03/pipeline_ex2/pip...</td>\n",
       "      <td>fraud</td>\n",
       "      <td>pipeline_ex2</td>\n",
       "      <td>run-20221004152128</td>\n",
       "      <td>03</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>us-central1</td>\n",
       "      <td>transaction_id</td>\n",
       "      <td>statmike-mlops-349915</td>\n",
       "      <td>{'rows': [{'row': [28449.0, 6.0]}, {'row': [10...</td>\n",
       "      <td>0.812876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   pipeline_name  \\\n",
       "0  series-03-endpoint-challenger   \n",
       "1  series-03-endpoint-challenger   \n",
       "\n",
       "                                       run_name param.input:var_target  \\\n",
       "0  series-03-endpoint-challenger-20221004192647                  Class   \n",
       "1  series-03-endpoint-challenger-20221004152232                  Class   \n",
       "\n",
       "  param.input:timestamp param.input:bq_table  \\\n",
       "0        20221004192552        fraud_prepped   \n",
       "1        20221004152128        fraud_prepped   \n",
       "\n",
       "                                     param.input:uri param.input:bq_dataset  \\\n",
       "0  gs://statmike-mlops-349915/03/pipeline_ex2/pip...                  fraud   \n",
       "1  gs://statmike-mlops-349915/03/pipeline_ex2/pip...                  fraud   \n",
       "\n",
       "  param.input:experiment param.input:run_name param.input:series  \\\n",
       "0           pipeline_ex2   run-20221004192552                 03   \n",
       "1           pipeline_ex2   run-20221004152128                 03   \n",
       "\n",
       "     param.input:project param.input:region param.input:var_omit  \\\n",
       "0  statmike-mlops-349915        us-central1       transaction_id   \n",
       "1  statmike-mlops-349915        us-central1       transaction_id   \n",
       "\n",
       "  param.input:bq_project                             metric.confusionMatrix  \\\n",
       "0  statmike-mlops-349915  {'rows': [{'row': [27969.0, 486.0]}, {'row': [...   \n",
       "1  statmike-mlops-349915  {'rows': [{'row': [28449.0, 6.0]}, {'row': [10...   \n",
       "\n",
       "   metric.auPRC  \n",
       "0      0.764713  \n",
       "1      0.812876  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiplatform.get_pipeline_df(pipeline = f'series-{SERIES}-endpoint-challenger')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33e69dc-2724-400a-8bb1-b4c349441dde",
   "metadata": {},
   "source": [
    "## Review Pipeline Run\n",
    "\n",
    "<p aligh=\"center\"><center><img src=\"../architectures/notebooks/03/pipeline_ex2.png\" width=\"75%\"></center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24191d22-46dd-4145-bbb9-ec4a6784a40a",
   "metadata": {},
   "source": [
    "---\n",
    "## Remove Resources\n",
    "see notebook \"99 - Cleanup\""
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-3.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m94"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
